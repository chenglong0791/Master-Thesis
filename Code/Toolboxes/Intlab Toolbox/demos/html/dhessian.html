
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>DEMOHESSIAN  Short demonstration of Hessians</title><meta name="generator" content="MATLAB 9.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-07-22"><meta name="DC.source" content="dhessian.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>DEMOHESSIAN  Short demonstration of Hessians</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Some sample applications of the Hessian toolbox</a></li><li><a href="#2">Initialization of Hessians</a></li><li><a href="#3">Access of the Hessian</a></li><li><a href="#9">A simple example</a></li><li><a href="#12">Hessians over ordinary intervals</a></li><li><a href="#13">Hessians over affine intervals</a></li><li><a href="#15">Zeros of a function</a></li><li><a href="#16">Extrema of a function</a></li><li><a href="#17">Inclusion of extrema</a></li><li><a href="#18">Functions in several unknowns</a></li><li><a href="#19">Approximation of an extremum</a></li><li><a href="#21">Inclusion of a stationary point</a></li><li><a href="#22">Inclusion of a minimum</a></li><li><a href="#24">A model problem in 5000 unknowns I</a></li><li><a href="#25">A model problem in 5000 unknowns II</a></li><li><a href="#26">A model problem in 5000 unknowns III</a></li><li><a href="#28">Verification of a minimum</a></li><li><a href="#30">Enjoy INTLAB</a></li></ul></div><h2 id="1">Some sample applications of the Hessian toolbox</h2><p>Hessians implement second order automatic differentiation in forward mode.</p><pre class="codeinput">format <span class="string">compact</span> <span class="string">long</span> <span class="string">_</span>
setround(0)                           <span class="comment">% set rounding to nearest</span>
</pre><h2 id="2">Initialization of Hessians</h2><p>The initialization follows the same principles as for gradients, for example</p><pre class="codeinput">x = hessianinit([ -.3 ; pi ])
</pre><pre class="codeoutput">Hessian value x.x = 
  -0.300000000000000
   3.141592653589793
Hessian derivative(s) x.dx = 
     1     0
     0     1
Hessian second derivative(s) x.hx(1,1,:,:) = 
     0     0
     0     0
Hessian second derivative(s) x.hx(2,1,:,:) = 
     0     0
     0     0
</pre><h2 id="3">Access of the Hessian</h2><p>Define the function f: R^n-&gt;R^n by</p><pre class="codeinput">f = @(x)( 3*x(1)*x + sin(x).*(sec(x)-sqrt(x)) )
</pre><pre class="codeoutput">f =
  function_handle with value:
    @(x)(3*x(1)*x+sin(x).*(sec(x)-sqrt(x)))
</pre><p>The number of unknowns is determined by the length of the input vector x. For example,</p><pre class="codeinput">f(1:4)
</pre><pre class="codeoutput">ans =
  Columns 1 through 3
   3.715936739847006   2.529019383490645   8.613026433001503
  Column 4
  14.671426272965434
</pre><p>The function can be evaluated using the Hessian package as follows:</p><pre class="codeinput">y = f(hessianinit([1.1 -2.7 pi]'));
</pre><p>There is direct access of the Hessian of y=f(x) by</p><pre class="codeinput">y.hx
</pre><pre class="codeoutput">ans(:,:,1,1) =
 25.793906481681820 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,2,1) =
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,3,1) =
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,1,2) =
  0.000000000000000 + 0.000000000000000i
  3.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,2,2) =
  3.000000000000000 + 0.000000000000000i
  1.156737479094823 - 1.276540468064363i
  0.000000000000000 + 0.000000000000000i
ans(:,:,3,2) =
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,1,3) =
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  3.000000000000000 + 0.000000000000000i
ans(:,:,2,3) =
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
ans(:,:,3,3) =
  3.000000000000000 + 0.000000000000000i
  0.000000000000000 + 0.000000000000000i
  0.564189583547756 + 0.000000000000000i
</pre><p>However, y.hx contains the Hessians of all three component functions of the original function f. To access the Hessians it is recommended to use the Hessian of individual components, not components of y.hx:</p><pre class="codeinput">H3 = y(3).hx
</pre><pre class="codeoutput">H3 =
                   0                   0   3.000000000000000
                   0                   0                   0
   3.000000000000000                   0   0.564189583547756
</pre><p>The matrix H3 is the Hessian of the third component function of f at x.</p><h2 id="9">A simple example</h2><p>Consider the following function</p><pre class="codeinput">f = inline(<span class="string">' sin(x-log(x+2))-x*cosh(x)/15 '</span>)
</pre><pre class="codeoutput">f =
     Inline function:
     f(x) = sin(x-log(x+2))-x*cosh(x)/15
</pre><p>To plot the function first vectorize f :</p><pre class="codeinput">F = vectorize(f)
</pre><pre class="codeoutput">F =
     Inline function:
     F(x) = sin(x-log(x+2))-x.*cosh(x)./15
</pre><p>Plot the function including the x-axis:</p><pre class="codeinput">x = linspace(-1,3); close; plot( x,F(x), x,0*x )
</pre><img vspace="5" hspace="5" src="dhessian_01.png" alt=""> <h2 id="12">Hessians over ordinary intervals</h2><p>The range of the function f and its first and second derivative over X=[1,2] is included by</p><pre class="codeinput">X = infsup(1,2);
Yint = f(hessianinit(X))
</pre><pre class="codeoutput">intval Hessian value Yint.x = 
[  -0.87838452581391,   0.68131672798366] 
intval Hessian derivative(s) Yint.dx = 
[  -0.32071287481175,   0.56878121143607] 
intval Hessian second derivative(s) value Yint.hx = 
[  -1.38753101700004,   0.06347219524331] 
</pre><h2 id="13">Hessians over affine intervals</h2><p>Better inclusions of the ranges may be computed by</p><pre class="codeinput">Yaff = f(hessianinit(affari(X)))
</pre><pre class="codeoutput">affari Hessian value Yaff.x = 
[  -0.22166634434316,   0.20542612815224] 
affari Hessian derivative(s) Yaff.dx = 
[  -0.12197001939730,   0.53947300076961] 
affari Hessian second derivative(s) value Yaff.hx = 
[  -1.25805672986527,  -0.08729371200877] 
</pre><p>For example, it becomes clear that the second derivative f" has no root in [1,2].</p><h2 id="15">Zeros of a function</h2><p>There are two roots near 1.5 and 2.5, and two extrema near -0.5 and 2. The roots can be included by verifynlss. For this simple function the inclusion is of maximum accuracy.</p><pre class="codeinput">X1 = verifynlss(f,1.5)
X2 = verifynlss(f,2.5)
</pre><pre class="codeoutput">intval X1 = 
   1.47132336560595
intval X2 = 
   2.25002867328683
</pre><h2 id="16">Extrema of a function</h2><p>The extrema can be approximated and included using Hessians. The following is one step of a simple Newton iteration starting at x=-0.5 :</p><pre class="codeinput">x = -0.5;
y = f(hessianinit(x));
x = x - y.hx\y.dx';
y
</pre><pre class="codeoutput">Hessian value y.x = 
  -0.749124828278367
Hessian derivative(s) y.dx = 
   0.113228338943107
Hessian second derivative(s) value y.hx = 
   0.468843719809578
</pre><h2 id="17">Inclusion of extrema</h2><p>Inclusions of the extrema of f are computed by verifylocalmin.</p><pre class="codeinput">X1 = verifylocalmin(f,-0.5)
X2 = verifylocalmin(f,2)
</pre><pre class="codeoutput">intval X1 = 
  -0.72343012456517
intval X2 = 
  1.0e-015 *
  -0.______________
</pre><h2 id="18">Functions in several unknowns</h2><p>Function with several unknowns are handled in a similar manner. Consider the following test function by N. Gould. It is taken from the Coconut collection of test function for global optimization, <a href="http://www.mat.univie.ac.at/~neum/glopt/coconut/benchmark/Library2.html">http://www.mat.univie.ac.at/~neum/glopt/coconut/benchmark/Library2.html</a> .</p><pre class="codeinput">f = inline(<span class="string">' x(3)-1 + sqr(x(1)) + sqr(x(2)) + sqr(x(3)+x(4)) + sqr(sin(x(3))) +  sqr(x(1))*sqr(x(2)) + x(4)-3 + sqr(sin(x(3))) + sqr(x(4)-1) + sqr(sqr(x(2))) + sqr(sqr(x(3)) + sqr(x(4)+x(1))) + sqr(x(1)-4 + sqr(sin(x(4))) + sqr(x(2))*sqr(x(3))) + sqr(sqr(sin(x(4)))) '</span>)
</pre><pre class="codeoutput">f =
     Inline function:
     f(x) = x(3)-1 + sqr(x(1)) + sqr(x(2)) + sqr(x(3)+x(4)) + sqr(sin(x(3))) +  sqr(x(1))*sqr(x(2)) + x(4)-3 + sqr(sin(x(3))) + sqr(x(4)-1) + sqr(sqr(x(2))) + sqr(sqr(x(3)) + sqr(x(4)+x(1))) + sqr(x(1)-4 + sqr(sin(x(4))) + sqr(x(2))*sqr(x(3))) + sqr(sqr(sin(x(4))))
</pre><h2 id="19">Approximation of an extremum</h2><p>On the Web-site the global minimum of that function in 4 unknowns is given as 5.7444 . We use a couple of a Newton iterations starting at x=ones(4,1) to approximate a stationary point:</p><pre class="codeinput">format <span class="string">short</span>
x = ones(4,1);
<span class="keyword">for</span> i=1:20
   y = f(hessianinit(x));
   x = x - y.hx\y.dx';
<span class="keyword">end</span>
x
y.dx
</pre><pre class="codeoutput">x =
    1.4599
   -0.0000
    0.0809
   -0.8111
ans =
   1.0e-15 *
    0.8882   -0.0000    0.1110   -0.8882
</pre><p>Now x is an approximation of a stationary point: The gradient of f evaluated at x is not too far from zero. Note that many iterations were necessary due to the poor quality of the initial approximation ones(4,1).</p><h2 id="21">Inclusion of a stationary point</h2><p>Using this approximation an inclusion of a stationary point of f is computed by (in this case the last parameter 1 is used to see intermediate results):</p><pre class="codeinput">format <span class="string">long</span>
X = verifylocalmin(f,x,[],1)
</pre><pre class="codeoutput">residual norm(f'(xs_k)), floating point iteration 1
ans =
     1.778307332460799e-15
residual norm(f'(xs_k)), floating point iteration 2
ans =
     9.945640348601413e-16
residual norm(f'(xs_k)), floating point iteration 3
ans =
     9.945640348601413e-16
interval iteration 1
intval X = 
   1.45986156438163
   0.00000000000000
   0.08089005653386
  -0.81111308458517
</pre><h2 id="22">Inclusion of a minimum</h2><p>The interval vector X includes a root of f', i.e. a stationary point xx of f. To prove that f has a minumum at xx we need to prove positive definiteness of the Hessian of f evaluated at xx. The interval vector X includes the stationary point xx of f. So we compute an inclusion Y of the Hessian at X.</p><p>Mathematically, for every x in X the following is true: Y.x is an inclusion of f(x), Y.dx is an inclusion of f'(x), and Y.hx is an inclusion of the Hessian of f at x. Especially, the Hessian of f evaluated at xx is included in Y.hx.</p><pre class="codeinput">Y = f(hessianinit(X));
format <span class="string">_</span>
Y.hx
</pre><pre class="codeoutput">intval ans = 
   9.0766678854428_   0.00000000000000   0.41981840965597   3.0793123311663_
   0.00000000000000   6.20966816386002   0.00000000000000   0.00000000000000
   0.41981840965597   0.00000000000000   7.7097852348661_   2.41981840965596
   3.0793123311663_   0.00000000000000   2.41981840965596  13.3722229587129_
</pre><p>This interval matrix contains obviously only diagonally dominant matrices, so the stationary point xx of f in X is indeed a (local) minimum.</p><h2 id="24">A model problem in 5000 unknowns I</h2><p>The next problem is taken from</p><p><a href="http://orfe.princeton.edu/~rvdb/ampl/nlmodels/cute/bdqrtic.mod">http://orfe.princeton.edu/~rvdb/ampl/nlmodels/cute/bdqrtic.mod</a></p><pre>  Source: Problem 61 in
     A.R. Conn, N.I.M. Gould, M. Lescrenier and Ph.L. Toint,
     "Performance of a multifrontal scheme for partially separable optimization",
      Report 88/4, Dept of Mathematics, FUNDP (Namur, B), 1988.
      Copyright (C) 2001 Princeton University
      All Rights Reserved
  see bottom of file test_h.m</pre><p>The model problem is</p><pre>   N = length(x);      % model problem: N = 1000, initial approximation x=ones(N,1);
   I = 1:N-4;
   y = sum( (-4*x(I)+3.0).^2 + ( x(I).^2 + 2*x(I+1).^2 + ...
             3*x(I+2).^2 + 4*x(I+3).^2 + 5*x(N).^2 ).^2 );</pre><p>This function is evaluated by</p><pre>   index = 2;
   y = test_h(x,index);</pre><h2 id="25">A model problem in 5000 unknowns II</h2><p>The given starting vector is x = ones(5000,1). Recall that y = f(hessianinit(x)) has 5000 elements in y.x, 2.5e7 elements in y.dx and 1.25e11 elements in y.hx. In full storage this would mean 1 TeraByte of storage.</p><p>The following calculates an inclusion of a stationary point of f by first performing a simple Newton iteration followed by a verification step for the nonlinear system. The Hessian is treated as full matrix, so the computation may take a while.</p><pre class="codeinput">n = 5000;
index = 2;
tic
X = verifylocalmin(<span class="string">'test_h'</span>,ones(n,1),[],1,index);
tfull = toc
max(relerr(X))
</pre><pre class="codeoutput">residual norm(f'(xs_k)), floating point iteration 1
ans =
     1.499415844035270e+06
residual norm(f'(xs_k)), floating point iteration 2
ans =
     4.442651106586590e+05
residual norm(f'(xs_k)), floating point iteration 3
ans =
     1.316745943265305e+05
residual norm(f'(xs_k)), floating point iteration 4
ans =
     3.902878013156915e+04
residual norm(f'(xs_k)), floating point iteration 5
ans =
     1.008486090604475e+04
residual norm(f'(xs_k)), floating point iteration 6
ans =
     9.990290941444043e+02
residual norm(f'(xs_k)), floating point iteration 7
ans =
  17.085974829564289
residual norm(f'(xs_k)), floating point iteration 8
ans =
   0.070681934486502
residual norm(f'(xs_k)), floating point iteration 9
ans =
   0.003385440115388
residual norm(f'(xs_k)), floating point iteration 10
ans =
     2.846875081065139e-06
residual norm(f'(xs_k)), floating point iteration 11
ans =
     2.594087847144788e-13
interval iteration 1
interval iteration 2
tfull =
   8.804310609594797
ans =
     5.993402063076835e-16
</pre><h2 id="26">A model problem in 5000 unknowns III</h2><p>Note the small maximum relative error of the inclusion of the result. Verification is faster when solving the nonlinear system treating the Hessian as sparse. This is done by the following.</p><pre class="codeinput">n = 5000;
index = 2;
tic
X = verifylocalmin(<span class="string">'test_h'</span>,ones(n,1),<span class="string">'SparseSPD'</span>,1,index);
tsparse = toc
tfull
maxrelerrX = max(relerr(X))
</pre><pre class="codeoutput">residual norm(f'(xs_k)), floating point iteration 1
ans =
     1.499415844035270e+06
residual norm(f'(xs_k)), floating point iteration 2
ans =
     4.442651106586590e+05
residual norm(f'(xs_k)), floating point iteration 3
ans =
     1.316745943265305e+05
residual norm(f'(xs_k)), floating point iteration 4
ans =
     3.902878013156915e+04
residual norm(f'(xs_k)), floating point iteration 5
ans =
     1.008486090604475e+04
residual norm(f'(xs_k)), floating point iteration 6
ans =
     9.990290941444043e+02
residual norm(f'(xs_k)), floating point iteration 7
ans =
  17.085974829564289
residual norm(f'(xs_k)), floating point iteration 8
ans =
   0.070681934486502
residual norm(f'(xs_k)), floating point iteration 9
ans =
   0.003385440115388
residual norm(f'(xs_k)), floating point iteration 10
ans =
     2.846875081065139e-06
residual norm(f'(xs_k)), floating point iteration 11
ans =
     2.594087847144788e-13
interval iteration 1
interval iteration 2
tsparse =
   1.003152754314012
tfull =
   8.804310609594797
maxrelerrX =
     8.647948578260549e-14
</pre><p>Note that verification is faster at the price of a less narrow inclusion (for comparison the previous time tfull is displayed).</p><h2 id="28">Verification of a minimum</h2><p>The solution X is already proved to include a (local) minimum. To verify that, the Hessian at X is computed which includes in particular the Hessian at the stationary point xhat in X.</p><pre class="codeinput">y = test_h(hessianinit(X),index);
isspd(y.hx)
</pre><pre class="codeoutput">ans =
  logical
   1
</pre><p>Then the interval Hessian is proved by "isspd" to be symmetric positive definite: Mathematically the result "isspd(M)=1" for a symmetric (Hermitian) interval matrix M proves that every symmetric (Hermitian) matrix A within M is positive definite. In our case in particular the Hermitian of f at the stationary point xhat. Therefore, xhat is proved to be a local minimum of f.</p><h2 id="30">Enjoy INTLAB</h2><p>INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing, Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% DEMOHESSIAN  Short demonstration of Hessians
%

%% Some sample applications of the Hessian toolbox
% Hessians implement second order automatic differentiation in forward mode.
%

format compact long _
setround(0)                           % set rounding to nearest

%% Initialization of Hessians
% The initialization follows the same principles as for gradients, for example

x = hessianinit([ -.3 ; pi ])

%% Access of the Hessian
% Define the function f: R^n->R^n by

f = @(x)( 3*x(1)*x + sin(x).*(sec(x)-sqrt(x)) )

%%
% The number of unknowns is determined by the length of the input vector x.
% For example,

f(1:4)

%%
% The function can be evaluated using the Hessian package as follows:

y = f(hessianinit([1.1 -2.7 pi]'));

%%
% There is direct access of the Hessian of y=f(x) by

y.hx

%%
% However, y.hx contains the Hessians of all three component functions of
% the original function f. To access the Hessians it is recommended to
% use the Hessian of individual components, not components of y.hx:

H3 = y(3).hx

%%
% The matrix H3 is the Hessian of the third component function of f at x.

%% A simple example
% Consider the following function
 
f = inline(' sin(x-log(x+2))-x*cosh(x)/15 ')
 
%% 
% To plot the function first vectorize f :
 
F = vectorize(f)
 
%% 
% Plot the function including the x-axis:
 
x = linspace(-1,3); close; plot( x,F(x), x,0*x )

%% Hessians over ordinary intervals
% The range of the function f and its first and second derivative over
% X=[1,2] is included by

X = infsup(1,2);
Yint = f(hessianinit(X))
 
%% Hessians over affine intervals
% Better inclusions of the ranges may be computed by

Yaff = f(hessianinit(affari(X)))

%%
% For example, it becomes clear that the second derivative f" has no root
% in [1,2].
 
%% Zeros of a function
% There are two roots near 1.5 and 2.5, and two extrema 
% near -0.5 and 2. The roots can be included by verifynlss.
% For this simple function the inclusion is of maximum accuracy.
 
X1 = verifynlss(f,1.5)
X2 = verifynlss(f,2.5)
  
%% Extrema of a function
% The extrema can be approximated and included using Hessians.
% The following is one step of a simple Newton iteration starting at x=-0.5 :
 
x = -0.5; 
y = f(hessianinit(x)); 
x = x - y.hx\y.dx';
y
  
%% Inclusion of extrema
% Inclusions of the extrema of f are computed by verifylocalmin.
 
X1 = verifylocalmin(f,-0.5)
X2 = verifylocalmin(f,2)
 
%% Functions in several unknowns
% Function with several unknowns are handled in a similar manner. 
% Consider the following test function by N. Gould. It is taken from
% the Coconut collection of test function for global optimization, 
% http://www.mat.univie.ac.at/~neum/glopt/coconut/benchmark/Library2.html .
 
f = inline(' x(3)-1 + sqr(x(1)) + sqr(x(2)) + sqr(x(3)+x(4)) + sqr(sin(x(3))) +  sqr(x(1))*sqr(x(2)) + x(4)-3 + sqr(sin(x(3))) + sqr(x(4)-1) + sqr(sqr(x(2))) + sqr(sqr(x(3)) + sqr(x(4)+x(1))) + sqr(x(1)-4 + sqr(sin(x(4))) + sqr(x(2))*sqr(x(3))) + sqr(sqr(sin(x(4)))) ')
 
%% Approximation of an extremum
% On the Web-site the global minimum of that function in 4 unknowns is 
% given as 5.7444 . We use a couple of a Newton iterations 
% starting at x=ones(4,1) to approximate a stationary point: 

format short
x = ones(4,1); 
for i=1:20
   y = f(hessianinit(x)); 
   x = x - y.hx\y.dx';
end
x
y.dx

%%
% Now x is an approximation of a stationary point:
% The gradient of f evaluated at x is not too far from zero.
% Note that many iterations were necessary due to the poor quality
% of the initial approximation ones(4,1).
   
%% Inclusion of a stationary point
% Using this approximation an inclusion of a stationary point of f is 
% computed by (in this case the last parameter 1 is used to see 
% intermediate results):
 
format long
X = verifylocalmin(f,x,[],1)

%% Inclusion of a minimum
% The interval vector X includes a root of f', i.e. a stationary point xx of f. To prove
% that f has a minumum at xx we need to prove positive definiteness of
% the Hessian of f evaluated at xx. The interval vector X includes the stationary point
% xx of f. So we compute an inclusion Y of the Hessian at X. 
%
% Mathematically,
% for every x in X the following is true: Y.x is an inclusion of f(x),
% Y.dx is an inclusion of f'(x), and Y.hx is an inclusion of the
% Hessian of f at x. Especially, the Hessian of f evaluated at xx is
% included in Y.hx. 
 
Y = f(hessianinit(X)); 
format _
Y.hx
  
%% 
% This interval matrix contains obviously only diagonally dominant
% matrices, so the stationary point xx of f in X is indeed a (local)
% minimum.  
%

%% A model problem in 5000 unknowns I
% The next problem is taken from 
%
% http://orfe.princeton.edu/~rvdb/ampl/nlmodels/cute/bdqrtic.mod
%
%    Source: Problem 61 in
%       A.R. Conn, N.I.M. Gould, M. Lescrenier and Ph.L. Toint,
%       "Performance of a multifrontal scheme for partially separable optimization",
%        Report 88/4, Dept of Mathematics, FUNDP (Namur, B), 1988.
%        Copyright (C) 2001 Princeton University
%        All Rights Reserved
%    see bottom of file test_h.m
% 
% The model problem is
%  
%     N = length(x);      % model problem: N = 1000, initial approximation x=ones(N,1);
%     I = 1:N-4;
%     y = sum( (-4*x(I)+3.0).^2 + ( x(I).^2 + 2*x(I+1).^2 + ...
%               3*x(I+2).^2 + 4*x(I+3).^2 + 5*x(N).^2 ).^2 );
% 
% This function is evaluated by
%
%     index = 2;
%     y = test_h(x,index);

%% A model problem in 5000 unknowns II
% The given starting vector is x = ones(5000,1).
% Recall that y = f(hessianinit(x)) has 5000 elements in y.x, 2.5e7 elements
% in y.dx and 1.25e11 elements in y.hx. In full storage this would mean 1 TeraByte
% of storage. 
%
% The following calculates an inclusion of a stationary point of f by first
% performing a simple Newton iteration followed by a verification step for
% the nonlinear system. The Hessian is treated as full matrix, so the 
% computation may take a while.
 
n = 5000;
index = 2;
tic
X = verifylocalmin('test_h',ones(n,1),[],1,index);
tfull = toc
max(relerr(X))
         
%% A model problem in 5000 unknowns III
% Note the small maximum relative error of the inclusion of the result.
% Verification is faster when solving the nonlinear system treating the
% Hessian as sparse. This is done by the following. 
 
n = 5000;
index = 2;
tic
X = verifylocalmin('test_h',ones(n,1),'SparseSPD',1,index);
tsparse = toc
tfull
maxrelerrX = max(relerr(X))
       
%% 
% Note that verification is faster at the price of a less narrow inclusion
% (for comparison the previous time tfull is displayed). 
% 

%% Verification of a minimum
% The solution X is already proved to include a (local) minimum. To verify
% that, the Hessian at X is computed which includes in particular the Hessian at the
% stationary point xhat in X. 
 
y = test_h(hessianinit(X),index); 
isspd(y.hx)
      
%%
% Then the interval Hessian is proved by "isspd" to be symmetric
% positive definite: Mathematically the result "isspd(M)=1" for a symmetric
% (Hermitian) interval matrix M proves that every symmetric (Hermitian) matrix
% A within M is positive definite. In our case in particular the Hermitian of f
% at the stationary point xhat. Therefore, xhat is proved to be a local minimum of f.

%% Enjoy INTLAB
% INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing,
% Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de

##### SOURCE END #####
--></body></html>