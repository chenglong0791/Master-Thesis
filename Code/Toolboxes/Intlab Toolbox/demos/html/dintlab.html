
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>DEMOINTLAB  A little demonstration of INTLAB, the Matlab toolbox for Reliable Computing</title><meta name="generator" content="MATLAB 9.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-07-22"><meta name="DC.source" content="dintlab.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>DEMOINTLAB  A little demonstration of INTLAB, the Matlab toolbox for Reliable Computing</h1><!--introduction--><p>Designed and written by Siegfried M. Rump, head of the Institute for Reliable Computing, Hamburg University of Technology. For more information, see www.ti3.tuhh.de</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Welcome to INTLAB, the Matlab toolbox for Reliable Computing</a></li><li><a href="#2">Possible overestimation by interval operations</a></li><li><a href="#3">The product Q*X: rotation of an interval</a></li><li><a href="#4">The product Q*X using affine arithmetic</a></li><li><a href="#6">Limited precision calculations: The fl-toolbox</a></li><li><a href="#8">An example of interval overestimation: complex multiplication</a></li><li><a href="#9">A model problem for global optimization proposed by Griewank</a></li><li><a href="#10">Find the minimum function value, kmax = 20</a></li><li><a href="#11">Find the minimum function value, kmax = 50</a></li><li><a href="#12">Estimation of the range of the Griewank-function over the whole domain by taking the minimum and maximum in the nodes</a></li><li><a href="#13">Inclusion of the range by interval arithmetic</a></li><li><a href="#14">Finding the global minimum</a></li><li><a href="#15">Parameter set estimation</a></li><li><a href="#17">A linear system in n=500 unknowns with random entries A_ij</a></li><li><a href="#18">Inclusion interval vector X of solution of the interval linear system Ax=b</a></li><li><a href="#19">How sharp is the computed inclusion?</a></li><li><a href="#21">Try a Monte Carlo approach</a></li><li><a href="#23">Use sign information of an approximate inverse of A.mid to obtain the true range</a></li><li><a href="#24">Inner inclusion</a></li><li><a href="#28">Structured linear systems</a></li><li><a href="#32">Roots of a polynomial in the complex plane</a></li><li><a href="#33">Calculate the range of P in the interval [-1,0.7]</a></li><li><a href="#34">Bernstein coefficients</a></li><li><a href="#35">Improvement of Bernstein bounds</a></li><li><a href="#36">Bernstein coefficients for interval polynomials</a></li><li><a href="#37">The solution complex of a linear interval system</a></li><li><a href="#38">Convexity of the solution set of an interval linear system</a></li><li><a href="#39">The solution set of a 3-dimensional interval linear system</a></li><li><a href="#41">A batman like example</a></li><li><a href="#42">Enjoy INTLAB</a></li></ul></div><h2 id="1">Welcome to INTLAB, the Matlab toolbox for Reliable Computing</h2><p>Following are some examples how to use INTLAB, the Matlab toolbox for Reliable Computing. Since I like pictures, some features using the graphical capabilities of INTLAB are demonstrated. Please consult "demo intval" [direct call web('dintval.html')] to get acquainted how to define and to use intervals. See also the other demos like gradient, hessian, long, polynom, etc.</p><h2 id="2">Possible overestimation by interval operations</h2><p>As a first example, watch possible overestimation by interval operations by the so-called wrapping effect. Define a 2 x 2 rotation matrix Q rotating by 30 degrees and consider the two-dimensional box X with lower left vertex (1,1) and upper right vertex</p><pre class="codeinput">format <span class="string">compact</span> <span class="string">short</span> <span class="string">infsup</span>

phi = 30*pi/180;
Q = [ cos(phi) -sin(phi) ; sin(phi) cos(phi) ]

X = [ infsup(1,2) ; infsup(2,4) ]
</pre><pre class="codeoutput">Q =
    0.8660   -0.5000
    0.5000    0.8660
intval X = 
[    1.0000,    2.0000] 
[    2.0000,    4.0000] 
</pre><h2 id="3">The product Q*X: rotation of an interval</h2><p>Distinguish between the power set operation Q*X and the interval operation Q*X. By linearity, the power set result is an n-dimensional parallel-epiped. The interval product Q*X, however, must be an interval vector. By definition, it is the smallest interval vector containing all possible Q*x for x in X. The overestimation is caused by the fact that the supporting hyperplanes of interval vectors are parallel to the axes. The following picture shows in blue the interval result of Q*X, while the parallelogram in red is the true range of Q*x for x in X.</p><pre class="codeinput">Yint = Q*X
close <span class="string">all</span>
plotintval(Yint,<span class="string">'n'</span>), hold <span class="string">on</span>
x = [1 1 2 2;2 4 2 4]; y = Q*x;
index = convhull(y(1,:),y(2,:));
plot(0,0,<span class="string">'o'</span>)
plot(x(1,index),x(2,index),<span class="string">'k--'</span>)
plot(y(1,index),y(2,index),<span class="string">'r-o'</span>)
axis <span class="string">equal</span>
hold <span class="string">off</span>
</pre><pre class="codeoutput">intval Yint = 
[   -1.1340,    0.7321] 
[    2.2320,    4.4642] 
</pre><img vspace="5" hspace="5" src="dintlab_01.png" alt=""> <h2 id="4">The product Q*X using affine arithmetic</h2><p>Affine operations carry some "memory" and may produce better inclusions. The following shows both the result using ordinary interval arithmetic and using affine arithmetic. The large red box is the result by ordinary interval arithmetic, the blue parallel-epiped inside the result by affine arithmetic.</p><pre class="codeinput">close
Yaff = Q*affari(X)
plotintval(Yint,<span class="string">'r'</span>)
hold <span class="string">on</span>
plotaffari(Yaff)
shg
</pre><pre class="codeoutput">affari Yaff = 
[   -1.1340,    0.7321] 
[    2.2320,    4.4642] 
</pre><img vspace="5" hspace="5" src="dintlab_02.png" alt=""> <p>It is important to note that INTLAB's affari package continues computations only with the intersection between the blue area and the rectangle.</p><p>The results can never be worse than ordinary interval arithmetic. For details see the affari demo.</p><h2 id="6">Limited precision calculations: The fl-toolbox</h2><p>Sometimes it is interesting to know the result of a computation using some limited precision. This is possible using the INTLAB's fl-toolbox. Consider the following residual of a linear system, first computed in working (double) precision, then using binary 22-bit arithmetic with exponent range 100:</p><pre class="codeinput">n = 100;
A = randn(n);
b = randn(n,1);
xs = A\b;
normresdble = max(abs(A*xs-b))
flinit(22,100)
normresfl = max(abs(A*fl(xs)-b))
flinit(<span class="string">'DisplayDouble'</span>)
normresfl
</pre><pre class="codeoutput">normresdble =
   2.2538e-14
ans =
    'Initialization of fl-format to 22 mantissa bits incl. impl. 1 and exponent range -99 .. 100 for normalized fl-numbers'
fl-type normresfl =
   1.2023e-05
===&gt; Display fl-variables as doubles
fl-type normresfl =
   1.2023e-05
</pre><p>As expected, the accuracy decreases. An inclusion of the residual is computed as follows, for details see the fl-demo:</p><pre class="codeinput">normres_incl = max(A*intval(xs)-b)
normres_fl_incl = max(A*fl(intval(xs))-b)
</pre><pre class="codeoutput">intval normres_incl = 
  1.0e-013 *
[    0.1215,    0.5327] 
fl-type intval normres_fl_incl =
  1.0e-003 *
[   -0.0206,    0.1045] 
</pre><h2 id="8">An example of interval overestimation: complex multiplication</h2><p>It is the principle of interval operations that they always produce a result which contains all possible results of operations between quantities in the input operands. Another example of overestimation is complex multiplication. The data for the following picture is taken from Markus Grimmer, Wuppertal, presented at the Dagstuhl meeting on "Numerical Software with Result Verification", January 2003. The blue circle is the (complex) interval result. Real intervals in INTLAB use inf-sup representation, while complex intervals use mid-rad representation.</p><pre class="codeinput">close <span class="string">all</span>
kmax = 40; i = sqrt(-1); a=midrad(1,1); b=midrad(-1+i,1);
plotintval(a*b); hold <span class="string">on</span>
phi = linspace(0,2*pi,kmax);
[A,B] = meshgrid( mid(a)+rad(a)*exp(i*phi) , mid(b)+rad(b)*exp(i*phi) );
plot(A.*B)
hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="dintlab_03.png" alt=""> <h2 id="9">A model problem for global optimization proposed by Griewank</h2><p>The amount of overestimation depends on many things, especially on the formulation of a function. As a rule thumb one might say that to diminish overestimation, a single variable should not occur too many times. However, there are many counterexamples to that.</p><p>Sometimes there is not much overestimation. As an example take the following well known test function for global optimization routines proposed by Griewank:</p><pre class="codeinput">f = inline(<span class="string">' (x.^2+y.^2)/4000 + cos(x).*cos(y)/sqrt(2) + 1 '</span>)
</pre><pre class="codeoutput">f =
     Inline function:
     f(x,y) = (x.^2+y.^2)/4000 + cos(x).*cos(y)/sqrt(2) + 1
</pre><h2 id="10">Find the minimum function value, kmax = 20</h2><p>The task for a global optimizer is to find the minimum function value for    -60 &lt;= x &lt;= 60    -60 &lt;= y &lt;= 60 To get an impression of the function we first take a look at a plot. The following is how it really happened to me.</p><pre class="codeinput">kmax = 20;
[x,y] = meshgrid(linspace(-60,60,kmax));
surf(x,y,f(x,y))
</pre><img vspace="5" hspace="5" src="dintlab_04.png" alt=""> <h2 id="11">Find the minimum function value, kmax = 50</h2><p>The surface looks smooth and one might argue why should this be a serious test function for global optimization. However, if we repeat the plot with 50 meshpoints in x- and y-direction, then the function decovers its ugly behaviour.</p><pre class="codeinput">kmax = 50;
[x,y] = meshgrid(linspace(-60,60,kmax));
surf(x,y,f(x,y))
</pre><img vspace="5" hspace="5" src="dintlab_05.png" alt=""> <h2 id="12">Estimation of the range of the Griewank-function over the whole domain by taking the minimum and maximum in the nodes</h2><p>The first plot looks nice just because of advantageous plotting nodes. We may try to estimate the range of the function over the whole domain by taking the minimum and maximum in the nodes. This is, by construction, always an inner inclusion.</p><pre class="codeinput">[ min(min(f(x,y))) max(max(f(x,y))) ]
</pre><pre class="codeoutput">ans =
    0.3901    3.4414
</pre><h2 id="13">Inclusion of the range by interval arithmetic</h2><p>A true inclusion is easily obtained by interval arithmetic.</p><p>Note that the first estimate required 50*50 = 2500 function evaluation, whereas the validated inclusion requires only one interval evaluation. A closer inspection shows that the interval bounds are sharp up to two digits, so in this case there is not much overestimation. Unfortunately, this is not always typical.</p><pre class="codeinput">X = infsup(-60,60); Y = X; f(X,Y)
</pre><pre class="codeoutput">intval ans = 
[    0.2928,    3.5072] 
</pre><h2 id="14">Finding the global minimum</h2><p>A main point of interval arithmetic and verification methods is that the computed results are mathematically correct. Using only floating-point arithmetic that is particularly difficult if the global behaviour of a function is to be estimated.</p><p>For example, finding the global minimum of the Griewank may be tried by local methods, possibly evaluating the function on a very fine grid. However, the true global minimum may slip such an approach.</p><p>A verification method computes the mathematically true global minimum, in the following of the Griewank function over the whole R^2. For more details on global optimization see the corresponding demo.</p><pre class="codeinput">tic
[mu,L] = verifyglobalmin(@Griewank,infsup(-inf,inf)*ones(2,1))
toc
</pre><pre class="codeoutput">intval mu = 
[    0.0000,    0.0000] 
L =
     []
Elapsed time is 0.991122 seconds.
</pre><h2 id="15">Parameter set estimation</h2><p>The following shows the areas where, in the box [-10,10]^2, the 2-dimensional Griewank function admits function values in the interval X:=[0,1].</p><pre class="codeinput">verifynlssparam(@Griewank,infsup(0,1),infsup(-10,10)*ones(2,1), <span class="keyword">...</span>
  verifynlssparamset(<span class="string">'display'</span>,<span class="string">'~'</span>));
</pre><img vspace="5" hspace="5" src="dintlab_06.png" alt=""> <p>Zooming into the picture shows red and yellow areas. For the former, all function values are inside X, for the latter they may be, and for the uncoloured boxes the function values are definitely outside X.</p><pre class="codeinput">axis([-2 -1 1 3])
shg
</pre><img vspace="5" hspace="5" src="dintlab_07.png" alt=""> <h2 id="17">A linear system in n=500 unknowns with random entries A_ij</h2><p>For a given linear system with data afflicted with tolerances one may want to compute the smallest box around the set of all solution for data varying within the tolerances. A common approach for that is Monte Carlo analysis.</p><p>Consider a randomly generated linear system with interval matrix A and right hand side b such that  A.mid * x = b  for x = ones(n,1). The following generates such a linear system in n=500 unknowns with random entries A_ij uniformly distributed within [-0.5,0.5] and each A_ij afflicted with a relative tolerance of 1e-6.</p><pre class="codeinput">n = 500; rand(<span class="string">'state'</span>,0)
A = rand(n)-.5; A = midrad(A,1e-6*abs(A)); b = A.mid*ones(n,1);
c = cond(A.mid)
</pre><pre class="codeoutput">c =
   3.3720e+03
</pre><h2 id="18">Inclusion interval vector X of solution of the interval linear system Ax=b</h2><p>The condition number c~1e3 suggests that we may expect a variation of the solution of the order c*1e-6 ~ 1e-3.</p><p>The following computes an inclusion X of the solution set of the interval linear system Ax=b, that is for every M in A the true solution of Mx=b is in X. The interval box of the first two components X(1) versus X(2) is plotted.</p><pre class="codeinput">close <span class="string">all</span>
tic
X = verifylss(A,b);
t_verifylss = toc
plotintval(X(1:2),<span class="string">'n'</span>)
hold <span class="string">on</span>
</pre><pre class="codeoutput">t_verifylss =
    0.1142
</pre><img vspace="5" hspace="5" src="dintlab_08.png" alt=""> <h2 id="19">How sharp is the computed inclusion?</h2><p>The size of the box is of the expected order, but is it an overestimation? Note that we know the expected size of X only because we computed the condition number of the (midpoint) matrix.</p><p>Often the sharpness of the computed inclusion can be judged by the computation of so-called inner inclusions. The following vectors Xinf and Xsup are computed such that [Xinf,Xsup] is in the inner of the best possible interval vector Xopt including the set of all solutions. The additional computing time is a marginal O(n^2).</p><pre class="codeinput">tic
[X,Xinf,Xsup] = verifylss(A,b);
t_verifylss = toc
Xinner = infsup(Xinf,Xsup);
plotintval(Xinner(1:2),<span class="string">'n'</span>)
</pre><pre class="codeoutput">t_verifylss =
    0.1044
</pre><img vspace="5" hspace="5" src="dintlab_09.png" alt=""> <p>From the small distance of the outer and inner inclusion it can be concluded that the computed outer inclusion is almost sharp.</p><h2 id="21">Try a Monte Carlo approach</h2><p>One may try a Monte Carlo approach. In order to obtain large variations of the solution we randomly choose only "vertex" matrices, that is matrices M such that M_ij is equal to A_ij.inf or A_ij.sup. We solve  100  such linear systems and plot the first two components of the result into the computed inclusion.</p><p>Note that this approach took of the order of 100*2n^3/3 operations. The random points suggest that the computed inclusion is quite an overestimation of the true range of the first two components. Note that we already proved that this is not true.</p><pre class="codeinput">tic
<span class="keyword">for</span> i=1:100
  a = A.mid+(rand(size(A))&gt;.5).*rad(A);
  x = a\b;
  plot(x(1),x(2),<span class="string">'o'</span>);
<span class="keyword">end</span>
t_MonteCarlo_100 = toc
t_verifylss
</pre><pre class="codeoutput">t_MonteCarlo_100 =
    2.0152
t_verifylss =
    0.1044
</pre><img vspace="5" hspace="5" src="dintlab_10.png" alt=""> <p>The 100 circles are so close together that they appear as one circle.</p><h2 id="23">Use sign information of an approximate inverse of A.mid to obtain the true range</h2><p>We may use sign information of an approximate inverse of A.mid to approximate extreme points of the true range of the solution. We do this for four linear systems, and the result is plotted into our figure by a circle 'o'. This confirms our previously computed inner inclusion.</p><pre class="codeinput">R = inv(A.mid);
<span class="keyword">for</span> i=1:2
  <span class="keyword">for</span> s=[-1 1]
    a = A.mid - s*(sign(R(i,:)')*ones(1,n)).*A.rad;
    x = a\b;
    plot(x(1),x(2),<span class="string">'ko'</span>)
  <span class="keyword">end</span>
<span class="keyword">end</span>
hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="dintlab_11.png" alt=""> <h2 id="24">Inner inclusion</h2><p>Inner inclusions can be computed if only one entry in the matrix is afflicted with a tolerance. As an example consider</p><pre class="codeinput">n = 1000;
A = intval(randn(n));
A(241,433) = midrad(1,0.05);
b = randn(n,1);
</pre><p>Some random entry of the input matrix is replaced by an interval, all other entries of the matrix and the right hand side are single floating-point numbers. An inner inclusion of the solution set is computed by</p><pre class="codeinput">[x,xinf,xsup] = verifylss(A,b);
</pre><p>The standard Matlab output or INTLAB output of infsup(xinf,xsup) would not display the inner inclusion correctly. For an inner inclusion, the displayed lower bound xinf should be greater or equal to the stored vector xinf, and similarly for xsup. This is achieved by the following:</p><pre class="codeinput">format <span class="string">short</span>
v = 1:4;
x(v)
displayinner(xinf(v),xsup(v))
</pre><pre class="codeoutput">intval ans = 
[    2.8606,    2.8717] 
[    1.9689,    1.9721] 
[    2.2452,    2.2505] 
[   -1.1866,   -1.1829] 
intval y = 
[    2.8607,    2.8716] 
[    1.9690,    1.9720] 
[    2.2453,    2.2504] 
[   -1.1865,   -1.1830] 
</pre><p>Note that the outer and inner inclusion almost coincide.</p><h2 id="28">Structured linear systems</h2><p>When solving a linear system with interval data, by default all data are assumed to vary independently within the tolerances. However, often the input data follows some structure, for example, the input matrix being restricted to persymmetric Hankel or circulant matrices.</p><p>Consider the following linear system, the matrix arising from the classic second difference operator on n points.</p><pre class="codeinput">n = 100;
e = midrad(ones(n,1),5e-5);
A = full(spdiags([e -2*e e],-1:1,n,n));
xs = ones(n,1);
xs(2:2:n) = -1;
b = A.mid*xs;
v = 1:5;
A.mid(v,v)
</pre><pre class="codeoutput">ans =
    -2     1     0     0     0
     1    -2     1     0     0
     0     1    -2     1     0
     0     0     1    -2     1
     0     0     0     1    -2
</pre><p>By construction, the matrix is symmetric Toeplitz. Note that we defined the matrix with tolerances, namely the off-diagonal elements of the matrix have a radius 5e-5, and the diagonal elements are afflicted with a radius of 1e-4. We defined a right hand side such that the true solution of the midpoint linear system is [1,-1,1,-1,...]'.</p><p>Our standard linear system solver computes an inclusion for input data varying independently within the tolerances.</p><pre class="codeinput">[x,xinf,xsup] = verifylss(A,b);
format <span class="string">infsup</span>
v = 47:53;
x(v)
displayinner(xinf(v),xsup(v))
</pre><pre class="codeoutput">intval ans = 
[    0.6783,    1.3217] 
[   -1.3225,   -0.6775] 
[    0.6769,    1.3231] 
[   -1.3233,   -0.6767] 
[    0.6767,    1.3233] 
[   -1.3231,   -0.6769] 
[    0.6775,    1.3225] 
intval y = 
[    0.8142,    1.1858] 
[   -1.1862,   -0.8138] 
[    0.8136,    1.1864] 
[   -1.1866,   -0.8134] 
[    0.8134,    1.1866] 
[   -1.1864,   -0.8136] 
[    0.8138,    1.1862] 
</pre><p>As can be seen, the inclusion of the solution is rather wide (we display only some components, the others are similar). However, the inner inclusion decovers that this inclusion is not too far from the narrowest inclusion of the solution set. This is true for input data varying independently within the matrix intervals.</p><p>Things change when restricting the matrix to symmetric Toeplitz structure. In our example this implies that the matrix depends only on two parameters. Note, however, that it is not sufficient to solve the four extreme cases because the dependence is nonlinear. Moreover, this would not prove that all matrices within the tolerances are nonsingular.</p><p>An inclusion of the solution of the structured linear system together with an inner inclusion (and, of course, the proof that all structured matrices within the tolerances are nonsingular) is computed by the following command. As before, only some entries are displayed, the others are similar.</p><pre class="codeinput">[y,yinf,ysup] = verifystructlss(structure(A,<span class="string">'symmetricToeplitz'</span>),b);
y(v)
max([diam(x) diam(y)])
</pre><pre class="codeoutput">intval ans = 
[    0.9999,    1.0001] 
[   -1.0001,   -0.9999] 
[    0.9999,    1.0001] 
[   -1.0001,   -0.9999] 
[    0.9999,    1.0001] 
[   -1.0001,   -0.9999] 
[    0.9999,    1.0001] 
ans =
    0.6466    0.0001
</pre><p>As can be seen, taking the structure into account produces a much narrower inclusion than for data varying independently within the tolerances. Moreover, the inner inclusion shows that the outer inclusion may still be narrowed, but not too much:</p><pre class="codeinput">[diam(y(v)) ysup(v)-yinf(v)]
</pre><pre class="codeoutput">ans =
   1.0e-03 *
    0.1338    0.0662
    0.1339    0.0661
    0.1340    0.0660
    0.1340    0.0660
    0.1340    0.0660
    0.1340    0.0660
    0.1339    0.0661
</pre><h2 id="32">Roots of a polynomial in the complex plane</h2><p>Consider the following polynomial of degree 20 with randomly generated coefficients uniformly distributed in [-1,1]. We plot the roots of the polynomial in the complex plane.</p><pre class="codeinput">n = 20, rand(<span class="string">'state'</span>,0)
P = randpoly(n)
r = roots(P);
plot(real(r),imag(r),<span class="string">'o'</span>)
</pre><pre class="codeoutput">n =
    20
polynom P[x] = 
   -0.5377  x^20  
    0.2137  x^19  
   -0.0280  x^18  
    0.7826  x^17  
    0.5242  x^16  
   -0.0871  x^15  
   -0.9630  x^14  
    0.6428  x^13  
   -0.1106  x^12  
    0.2309  x^11  
    0.5839  x^10  
    0.8436  x^ 9  
    0.4764  x^ 8  
   -0.6475  x^ 7  
   -0.1886  x^ 6  
    0.8709  x^ 5  
    0.8338  x^ 4  
   -0.1795  x^ 3  
    0.7873  x^ 2  
   -0.8842  x     
   -0.2943        
</pre><img vspace="5" hspace="5" src="dintlab_12.png" alt=""> <h2 id="33">Calculate the range of P in the interval [-1,0.7]</h2><p>The roots are not too far from the unit circle, as expected.</p><p>Suppose we wish to calculate the range of P in the real interval [-1,0.7]. The easiest way is interval evaluation. We plot the polynomial and the inclusion of the range computed by (naive) interval arithmetic.</p><pre class="codeinput">a = -1; b = 0.7;
X = infsup(a,b);
Y = P{X}
plotpoly(P,a,b)
hold <span class="string">on</span>
</pre><pre class="codeoutput">intval Y = 
[   -3.8947,    4.8492] 
</pre><img vspace="5" hspace="5" src="dintlab_13.png" alt=""> <h2 id="34">Bernstein coefficients</h2><p>Obviously, the computed inclusion Y is a true inclusion of the range, but an overestimation. We can improve that by using Bernstein coefficients.</p><p>Bernstein coefficients are computed with respect to the defining interval [0,1]. If we transform [a,b] into that interval and compute the Bernstein coefficients, then the convex hull of the latter are an inclusion of the range of the polynomial.</p><pre class="codeinput">B = bernsteincoeff(ptrans(P,a,b,0,1));
plotbernstein(B,a,b)
hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="dintlab_14.png" alt=""> <h2 id="35">Improvement of Bernstein bounds</h2><p>The green line is the convex hull of the Bernstein coefficients. The upper bound is sharp, but the lower bound is still improvable. We may do so by splitting the interval into two parts, for example into [-1,-0.2] and [-.2,0.7], and transform both into [-1,1], one after the other.</p><pre class="codeinput">plotpoly(P,a,b), hold <span class="string">on</span>
a = -1; b = -.2;
B = bernsteincoeff(ptrans(P,a,b,0,1));
plotbernstein(B,a,b),
a = -.2; b = .7;
B = bernsteincoeff(ptrans(P,a,b,0,1));
plotbernstein(B,a,b), hold <span class="string">off</span>
</pre><img vspace="5" hspace="5" src="dintlab_15.png" alt=""> <h2 id="36">Bernstein coefficients for interval polynomials</h2><p>Bernstein coefficients may be computed for interval polynomials as well. Following is an example plotted in the interval [-1,2]. The blue and red lines are the lower and upper bound of the interval polynomial, respectively, and the green lines form the Bernstein bounds.</p><pre class="codeinput">P = polynom([infsup(1,2) infsup(-4,2) infsup(-3,1)])

a = -1; b = 2;
plotpoly(P,a,b), hold <span class="string">on</span>

B = bernsteincoeff(ptrans(P,a,b,0,1));
plotbernstein(B,a,b)
hold <span class="string">off</span>
</pre><pre class="codeoutput">intval polynom P[x] = 
[    1.0000,    2.0000]   x^2  
[   -4.0000,    2.0000]   x    
[   -3.0000,    1.0000]        
</pre><img vspace="5" hspace="5" src="dintlab_16.png" alt=""> <h2 id="37">The solution complex of a linear interval system</h2><p>The solution complex of a linear interval system is known to be convex in every orthant. Here is a simple example.</p><pre class="codeinput">A = [infsup(2,4) infsup(-1,0);infsup(0,1) infsup(1,2)];
b = [infsup(-2,5);1];
plotlinsol(A,b)
</pre><pre class="codeoutput">intval ans = 
[   -1.0000,    3.0000] 
[   -1.5000,    2.0000] 
</pre><img vspace="5" hspace="5" src="dintlab_17.png" alt=""> <h2 id="38">Convexity of the solution set of an interval linear system</h2><p>At first sight this looks like a contradiction. However, when plotting the axes, convexity in every orthant becomes clear.</p><pre class="codeinput">plotlinsol(A,b,1)
</pre><pre class="codeoutput">intval ans = 
[   -1.0000,    3.0000] 
[   -1.5000,    2.0000] 
</pre><img vspace="5" hspace="5" src="dintlab_18.png" alt=""> <h2 id="39">The solution set of a 3-dimensional interval linear system</h2><p>The solution set of a 3-dimensional linear system can also be displayed by plotlinsol. The following commands reproduce the cover page of Arnold's book.</p><pre class="codeinput">format <span class="string">infsup</span>
A = ones(3)*infsup(0,2);
A(1:4:end) = 3.5
b = ones(3,1)*infsup(-1,1)
close
plotlinsol(A,b)
</pre><pre class="codeoutput">intval A = 
[    3.5000,    3.5000] [    0.0000,    2.0000] [    0.0000,    2.0000] 
[    0.0000,    2.0000] [    3.5000,    3.5000] [    0.0000,    2.0000] 
[    0.0000,    2.0000] [    0.0000,    2.0000] [    3.5000,    3.5000] 
intval b = 
[   -1.0000,    1.0000] 
[   -1.0000,    1.0000] 
[   -1.0000,    1.0000] 
intval ans = 
[   -1.7648,    1.7648] 
[   -1.7648,    1.7648] 
[   -1.7648,    1.7648] 
</pre><img vspace="5" hspace="5" src="dintlab_19.png" alt=""> <p>In this demo the graph is produced before-hand. Executing the above commands in INTLAB shows the same graph, but by moving the cursor within the graph you may watch the solution set from different angles.</p><h2 id="41">A batman like example</h2><p>Some solution sets have nice shapes. Following is a batman-like example.</p><pre class="codeinput">A = [infsup(2,4) infsup(-1,1);infsup(-1,1) infsup(2,4)]
b = [infsup(-3,3);.8],
close
plotlinsol(A,b)
title(<span class="string">'batman'</span>)
</pre><pre class="codeoutput">intval A = 
[    2.0000,    4.0000] [   -1.0000,    1.0000] 
[   -1.0000,    1.0000] [    2.0000,    4.0000] 
intval b = 
[   -3.0000,    3.0000] 
[    0.8000,    0.8001] 
intval ans = 
[   -2.2667,    2.2667] 
[   -0.4667,    1.5334] 
</pre><img vspace="5" hspace="5" src="dintlab_20.png" alt=""> <h2 id="42">Enjoy INTLAB</h2><p>INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing, Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% DEMOINTLAB  A little demonstration of INTLAB, the Matlab toolbox for Reliable Computing
% Designed and written by Siegfried M. Rump, head of the Institute for Reliable Computing, Hamburg University of Technology.
% For more information, see www.ti3.tuhh.de

%% Welcome to INTLAB, the Matlab toolbox for Reliable Computing 
% Following are some examples how to use INTLAB, the Matlab toolbox for 
% Reliable Computing. 
% Since I like pictures, some features using the graphical capabilities 
% of INTLAB are demonstrated.
% Please consult "demo intval" [direct call web('dintval.html')] to get 
% acquainted how to define and to use intervals. See also
% the other demos like gradient, hessian, long, polynom, etc.
%
%% Possible overestimation by interval operations
% As a first example, watch possible overestimation by interval operations
% by the so-called wrapping effect.
% Define a 2 x 2 rotation matrix Q rotating by 30 degrees and consider the
% two-dimensional box X with lower left vertex (1,1) and upper right vertex

format compact short infsup

phi = 30*pi/180;
Q = [ cos(phi) -sin(phi) ; sin(phi) cos(phi) ]

X = [ infsup(1,2) ; infsup(2,4) ]
 
 
%% The product Q*X: rotation of an interval
% Distinguish between the power set operation Q*X and the interval operation Q*X.
% By linearity, the power set result is an n-dimensional parallel-epiped. The interval
% product Q*X, however, must be an interval vector. By definition, it is the smallest interval
% vector containing all possible Q*x for x in X. 
% The overestimation is caused by the fact that the supporting hyperplanes 
% of interval vectors are parallel to the axes. 
% The following picture shows in blue the interval result
% of Q*X, while the parallelogram in red is the true range of Q*x for x in X.
 
Yint = Q*X
close all
plotintval(Yint,'n'), hold on
x = [1 1 2 2;2 4 2 4]; y = Q*x;
index = convhull(y(1,:),y(2,:));
plot(0,0,'o')
plot(x(1,index),x(2,index),'kREPLACE_WITH_DASH_DASH')
plot(y(1,index),y(2,index),'r-o')
axis equal
hold off

%% The product Q*X using affine arithmetic
% Affine operations carry some "memory" and may produce better inclusions.
% The following shows both the result using ordinary interval arithmetic
% and using affine arithmetic. The large red box is the result by ordinary
% interval arithmetic, the blue parallel-epiped inside the result by affine
% arithmetic. 

close
Yaff = Q*affari(X)
plotintval(Yint,'r')
hold on
plotaffari(Yaff)
shg

%%
% It is important to note that INTLAB's affari package continues
% computations only with the intersection between the blue area and the
% rectangle. 
%
% The results can never be worse than ordinary interval arithmetic. For
% details see the affari demo.

%% Limited precision calculations: The fl-toolbox
% Sometimes it is interesting to know the result of a computation using
% some limited precision. This is possible using the INTLAB's fl-toolbox.
% Consider the following residual of a linear system, first computed in
% working (double) precision, then using binary 22-bit arithmetic with
% exponent range 100:

n = 100;
A = randn(n);
b = randn(n,1);
xs = A\b;
normresdble = max(abs(A*xs-b))
flinit(22,100)
normresfl = max(abs(A*fl(xs)-b))
flinit('DisplayDouble')
normresfl

%%
% As expected, the accuracy decreases. An inclusion of the residual is
% computed as follows, for details see the fl-demo:

normres_incl = max(A*intval(xs)-b)
normres_fl_incl = max(A*fl(intval(xs))-b)
 
%% An example of interval overestimation: complex multiplication
% It is the principle of interval operations that they always produce a result which
% contains all possible results of operations between quantities in the input operands.
% Another example of overestimation is complex multiplication. The data for the following
% picture is taken from Markus Grimmer, Wuppertal, presented at the Dagstuhl meeting on 
% "Numerical Software with Result Verification", January 2003. The blue circle is the
% (complex) interval result. Real intervals in INTLAB use inf-sup representation, while
% complex intervals use mid-rad representation.
%
 
close all
kmax = 40; i = sqrt(-1); a=midrad(1,1); b=midrad(-1+i,1); 
plotintval(a*b); hold on
phi = linspace(0,2*pi,kmax);
[A,B] = meshgrid( mid(a)+rad(a)*exp(i*phi) , mid(b)+rad(b)*exp(i*phi) );
plot(A.*B)
hold off
 
%% A model problem for global optimization proposed by Griewank
% The amount of overestimation depends on many things, especially on the formulation of
% a function. As a rule thumb one might say that to diminish overestimation, a single
% variable should not occur too many times. However, there are many counterexamples
% to that. 
%
% Sometimes there is not much overestimation. As an example take the following well known
% test function for global optimization routines proposed by Griewank:
 
f = inline(' (x.^2+y.^2)/4000 + cos(x).*cos(y)/sqrt(2) + 1 ')
 
%% Find the minimum function value, kmax = 20
% The task for a global optimizer is to find the minimum function value for 
%    -60 <= x <= 60
%    -60 <= y <= 60
% To get an impression of the function we first take a look at a plot. The following is
% how it really happened to me.
 
kmax = 20;
[x,y] = meshgrid(linspace(-60,60,kmax));
surf(x,y,f(x,y))

%%  Find the minimum function value, kmax = 50
% The surface looks smooth and one might argue why should this be a serious 
% test function for global optimization. However, if we repeat the plot with 
% 50 meshpoints in x- and
% y-direction, then the function decovers its ugly behaviour.
 
kmax = 50;
[x,y] = meshgrid(linspace(-60,60,kmax));
surf(x,y,f(x,y))
 
%% Estimation of the range of the Griewank-function over the whole domain by taking the minimum and maximum in the nodes
% The first plot looks nice just because of advantageous plotting nodes. 
% We may try to estimate the range of the function over the whole domain
% by taking the minimum and maximum in the nodes. This is, by construction,
% always an inner inclusion. 
 
[ min(min(f(x,y))) max(max(f(x,y))) ]

%% Inclusion of the range by interval arithmetic
% A true inclusion is easily obtained by interval arithmetic.
%
% Note that the first estimate required 50*50 = 2500 function evaluation, whereas
% the validated inclusion requires only one interval evaluation. A closer inspection
% shows that the interval bounds are sharp up to two digits,
% so in this case there is not much overestimation. Unfortunately, this is not always typical.

X = infsup(-60,60); Y = X; f(X,Y)

%% Finding the global minimum
% A main point of interval arithmetic and verification methods is that the
% computed results are mathematically correct. Using only floating-point
% arithmetic that is particularly difficult if the global behaviour of a
% function is to be estimated. 
%
% For example, finding the global minimum of the Griewank may be tried by
% local methods, possibly evaluating the function on a very fine grid.
% However, the true global minimum may slip such an approach.
%
% A verification method computes the mathematically true global minimum, in
% the following of the Griewank function over the whole R^2. For more details 
% on global optimization see the corresponding demo.

tic
[mu,L] = verifyglobalmin(@Griewank,infsup(-inf,inf)*ones(2,1))
toc

%% Parameter set estimation
% The following shows the areas where, in the box [-10,10]^2, the 2-dimensional 
% Griewank function admits function values in the interval X:=[0,1].

verifynlssparam(@Griewank,infsup(0,1),infsup(-10,10)*ones(2,1), ...
  verifynlssparamset('display','~'));

%%
% Zooming into the picture shows red and yellow areas. For the former, all
% function values are inside X, for the latter they may be, and for the
% uncoloured boxes the function values are definitely outside X.

axis([-2 -1 1 3])
shg

 
%% A linear system in n=500 unknowns with random entries A_ij
% For a given linear system with data afflicted with tolerances one may want to 
% compute the smallest box around the set of all solution for data varying within
% the tolerances. A common approach for that is Monte Carlo analysis. 
% 
% Consider a randomly generated linear system with interval matrix A and right hand side b
% such that  A.mid * x = b  for x = ones(n,1). The following generates such a linear system
% in n=500 unknowns with random entries A_ij uniformly distributed within [-0.5,0.5] and
% each A_ij afflicted with a relative tolerance of 1e-6. 
 
n = 500; rand('state',0)
A = rand(n)-.5; A = midrad(A,1e-6*abs(A)); b = A.mid*ones(n,1);
c = cond(A.mid)
 
%% Inclusion interval vector X of solution of the interval linear system Ax=b
% The condition number c~1e3 suggests that we may expect a variation of the solution
% of the order c*1e-6 ~ 1e-3. 
%
% The following computes an inclusion X of the solution set of the 
% interval linear system Ax=b, that is for every M in A the true solution of 
% Mx=b is in X.
% The interval box of the first two components X(1) versus X(2) is plotted.
 
close all
tic
X = verifylss(A,b); 
t_verifylss = toc
plotintval(X(1:2),'n')
hold on
 
%% How sharp is the computed inclusion?
% The size of the box is of the expected order, but is it an overestimation? Note that we 
% know the expected size of X only because we computed the condition number of the (midpoint)
% matrix. 
%
% Often the sharpness of the computed inclusion can be judged by the computation of so-called 
% inner inclusions. The following vectors Xinf and Xsup are computed such that [Xinf,Xsup] is in the 
% inner of the best possible interval vector Xopt including the set of all solutions. The additional
% computing time is a marginal O(n^2).

tic
[X,Xinf,Xsup] = verifylss(A,b); 
t_verifylss = toc
Xinner = infsup(Xinf,Xsup);
plotintval(Xinner(1:2),'n')

%%
% From the small distance of the outer and inner inclusion it can be concluded that the computed
% outer inclusion is almost sharp.


%% Try a Monte Carlo approach
% One may try a Monte Carlo approach. In order to obtain large variations of the solution
% we randomly choose only "vertex" matrices, that is matrices M such that M_ij is equal to A_ij.inf 
% or A_ij.sup. We solve  100  such linear systems and plot the first two 
% components of the result into the computed inclusion. 
%
% Note that this approach took of the order of 100*2n^3/3 operations. The random points suggest
% that the computed inclusion is quite an overestimation of the true range of the first
% two components. Note that we already proved that this is not true. 
% 
 
tic
for i=1:100
  a = A.mid+(rand(size(A))>.5).*rad(A); 
  x = a\b; 
  plot(x(1),x(2),'o');
end
t_MonteCarlo_100 = toc
t_verifylss

%%
% The 100 circles are so close together that they appear as one circle.
 
%% Use sign information of an approximate inverse of A.mid to obtain the true range
% We may use sign information of an approximate inverse of A.mid to approximate extreme points of 
% the true range of the solution. We do this for four linear systems, and the result is plotted 
% into our figure by a circle 'o'. This confirms our previously computed inner inclusion.
 
R = inv(A.mid);
for i=1:2
  for s=[-1 1]
    a = A.mid - s*(sign(R(i,:)')*ones(1,n)).*A.rad;
    x = a\b;
    plot(x(1),x(2),'ko')
  end
end
hold off
 
%% Inner inclusion
% Inner inclusions can be computed if only one entry in the matrix is afflicted with a tolerance. As
% an example consider

n = 1000;
A = intval(randn(n));
A(241,433) = midrad(1,0.05);
b = randn(n,1);

%%
% Some random entry of the input matrix is replaced by an interval, all other entries of the matrix
% and the right hand side are single floating-point numbers. An inner inclusion of the solution set
% is computed by

[x,xinf,xsup] = verifylss(A,b);

%%
% The standard Matlab output or INTLAB output of infsup(xinf,xsup) would not display the inner inclusion
% correctly. For an inner inclusion, the displayed lower bound xinf should be greater or equal
% to the stored vector xinf, and similarly for xsup. This is achieved by the following:

format short
v = 1:4;
x(v)
displayinner(xinf(v),xsup(v))

%%
% Note that the outer and inner inclusion almost coincide.


%% Structured linear systems
% When solving a linear system with interval data, by default all data are assumed to vary
% independently within the tolerances. However, often the input data
% follows some structure, for example, the input matrix being restricted to persymmetric 
% Hankel or circulant matrices.
%
% Consider the following linear system, the matrix arising from the classic second difference
% operator on n points.

n = 100;
e = midrad(ones(n,1),5e-5); 
A = full(spdiags([e -2*e e],-1:1,n,n));
xs = ones(n,1);
xs(2:2:n) = -1;
b = A.mid*xs;
v = 1:5;
A.mid(v,v)

%%
% By construction, the matrix is symmetric Toeplitz. Note that we defined the matrix with tolerances, 
% namely the off-diagonal elements of the matrix have a radius 5e-5, and the diagonal elements
% are afflicted with a radius of 1e-4.
% We defined a right hand side such that 
% the true solution of the midpoint linear system is [1,-1,1,-1,...]'.
%
% Our standard linear system solver computes an inclusion for input data varying independently
% within the tolerances. 

[x,xinf,xsup] = verifylss(A,b);
format infsup
v = 47:53;
x(v)
displayinner(xinf(v),xsup(v))

%%
% As can be seen, the inclusion of the solution is rather wide (we display only some components, the
% others are similar). However, the inner inclusion decovers that this inclusion is not too far from
% the narrowest inclusion of the solution set. 
% This is true for input data varying independently within the matrix intervals.
%
% Things change when restricting the matrix to symmetric Toeplitz structure. In our example 
% this implies that the
% matrix depends only on two parameters. Note, however, that it is not sufficient to solve the four
% extreme cases because the dependence is nonlinear. Moreover, this would not prove that all
% matrices within the tolerances are nonsingular.
%
% An inclusion of the solution of the structured linear system together with an inner inclusion 
% (and, of course, the proof that all structured matrices within the tolerances are nonsingular) 
% is computed by the following command. As before, only some entries are displayed, the others are
% similar.

[y,yinf,ysup] = verifystructlss(structure(A,'symmetricToeplitz'),b);
y(v)
max([diam(x) diam(y)])

%%
% As can be seen, taking the structure into account produces a much narrower inclusion
% than for data varying independently within the tolerances. Moreover,
% the inner inclusion shows that the outer inclusion may still be narrowed, but not too much:

[diam(y(v)) ysup(v)-yinf(v)]

%% Roots of a polynomial in the complex plane
% Consider the following polynomial of degree 20 with randomly generated coefficients
% uniformly distributed in [-1,1]. We plot the roots of the polynomial in the complex plane.
 
n = 20, rand('state',0)
P = randpoly(n)
r = roots(P); 
plot(real(r),imag(r),'o')

%% Calculate the range of P in the interval [-1,0.7]
% The roots are not too far from the unit circle, as expected.
%
% Suppose we wish to calculate the range of P in the real interval [-1,0.7]. The easiest
% way is interval evaluation. We plot the polynomial and the inclusion of the range
% computed by (naive) interval arithmetic.
%
 
a = -1; b = 0.7; 
X = infsup(a,b); 
Y = P{X}
plotpoly(P,a,b)
hold on

%% Bernstein coefficients
%
% Obviously, the computed inclusion Y is a true inclusion of the range, but an overestimation.
% We can improve that by using Bernstein coefficients. 
%
% Bernstein coefficients are computed with respect to the defining interval [0,1]. If we
% transform [a,b] into that interval and compute the Bernstein coefficients, then 
% the convex hull of the latter are an inclusion of the range of the polynomial. 
  
B = bernsteincoeff(ptrans(P,a,b,0,1)); 
plotbernstein(B,a,b)
hold off

%% Improvement of Bernstein bounds
% The green line is the convex hull of the Bernstein coefficients. The upper bound is
% sharp, but the lower bound is still improvable. We may do so by splitting the interval
% into two parts, for example into [-1,-0.2] and [-.2,0.7], and transform both into [-1,1],
% one after the other.
 
plotpoly(P,a,b), hold on
a = -1; b = -.2; 
B = bernsteincoeff(ptrans(P,a,b,0,1)); 
plotbernstein(B,a,b), 
a = -.2; b = .7; 
B = bernsteincoeff(ptrans(P,a,b,0,1)); 
plotbernstein(B,a,b), hold off

%% Bernstein coefficients for interval polynomials
% Bernstein coefficients may be computed for interval polynomials as well. Following is an
% example plotted in the interval [-1,2]. The blue and red lines are the lower and upper
% bound of the interval polynomial, respectively, and the green lines form the Bernstein bounds.
 
P = polynom([infsup(1,2) infsup(-4,2) infsup(-3,1)])
 
a = -1; b = 2;
plotpoly(P,a,b), hold on
 
B = bernsteincoeff(ptrans(P,a,b,0,1)); 
plotbernstein(B,a,b)
hold off
 
%% The solution complex of a linear interval system
% The solution complex of a linear interval system is known to be convex in every orthant. 
% Here is a simple example.
  
A = [infsup(2,4) infsup(-1,0);infsup(0,1) infsup(1,2)]; 
b = [infsup(-2,5);1];
plotlinsol(A,b)
 
%% Convexity of the solution set of an interval linear system
% At first sight this looks like a contradiction. However, when plotting the axes, convexity
% in every orthant becomes clear.
 
plotlinsol(A,b,1)

%% The solution set of a 3-dimensional interval linear system
% The solution set of a 3-dimensional linear system can also be displayed by plotlinsol. 
% The following commands reproduce the cover page of Arnold's book. 

format infsup
A = ones(3)*infsup(0,2); 
A(1:4:end) = 3.5
b = ones(3,1)*infsup(-1,1)
close
plotlinsol(A,b)

%%
% In this demo the graph is produced before-hand. Executing the above commands in INTLAB shows
% the same graph, but by moving the cursor within the graph you may watch the solution set from 
% different angles.

%% A batman like example
% Some solution sets have nice shapes. Following is a batman-like example.
 
A = [infsup(2,4) infsup(-1,1);infsup(-1,1) infsup(2,4)]
b = [infsup(-3,3);.8],
close
plotlinsol(A,b)
title('batman')

%% Enjoy INTLAB
% INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing,
% Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de

 
##### SOURCE END #####
--></body></html>