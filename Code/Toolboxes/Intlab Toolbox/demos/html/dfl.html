
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>DEMOFL  A demonstration of fl-numbers: k-bit arithmetic</title><meta name="generator" content="MATLAB 9.3"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2017-07-22"><meta name="DC.source" content="dfl.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>DEMOFL  A demonstration of fl-numbers: k-bit arithmetic</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Initialization</a></li><li><a href="#3">Comparison to IEEE754 single precision</a></li><li><a href="#5">Rounding into k bits</a></li><li><a href="#7">The relative rounding error unit</a></li><li><a href="#8">Basic operations</a></li><li><a href="#9">Output format</a></li><li><a href="#12">Checking theorems in k-bit arithmetic I</a></li><li><a href="#14">Checking theorems in k-bit arithmetic II</a></li><li><a href="#16">Predecessor and successor</a></li><li><a href="#17">Vector and matrix operations</a></li><li><a href="#18">Sparse matrices</a></li><li><a href="#19">Matrix routines</a></li><li><a href="#21">Doubled precision accumulation of dot products</a></li><li><a href="#24">Mixed precisions</a></li><li><a href="#27">Operator precedence</a></li><li><a href="#29">Interval operations</a></li><li><a href="#31">Interval vectors and matrices</a></li><li><a href="#33">Specification of intervals</a></li><li><a href="#35">Directed rounding</a></li><li><a href="#36">Mixing precision and double rounding</a></li><li><a href="#38">Enjoy INTLAB</a></li></ul></div><h2 id="1">Initialization</h2><p>Recently we published some papers showing that in the famous Wilkinson estimates factors gamma_n can often be replaced by n*eps. For testing purposes, the fl-package simulates IEEE 754 k-bit arithmetic including over- and underflow, exceptional values, directed rounding and alike.</p><p>To work, for example, with k bits precision and exponent range -E+1 ... E use</p><pre class="codeinput">k = 5;
E = 20;
flinit(k,E);
</pre><p>The precision and the exponent range are limited to</p><pre class="language-matlab">1 &lt;= prec &lt;= 26   and   <span class="string">1</span> <span class="string">&lt;=</span> <span class="string">expBias</span> <span class="string">&lt;=</span> <span class="string">484</span>
</pre><p>in order to achieve high performance of all operations. To retrieve the current setting of precision and exponent range use</p><pre class="codeinput">flinit
</pre><pre class="codeoutput">fl-format set to 5 mantissa bits incl. impl. 1 and exponent range -19 .. 20 for normalized fl-numbers</pre><h2 id="3">Comparison to IEEE754 single precision</h2><p>Using flinit(24,127), the set of fl-numbers is identical to IEEE754 single precision. However, library routines in Matlab may use a different order to compute, for example, dot products, so that results in single and fl-arithmetic may be different. Consider</p><pre class="codeinput">flinit(24,127);             <span class="comment">% same as IEEE754 single precision</span>
x = single(randn(1000,1));  <span class="comment">% random single precision vector</span>
all(x == fl(x))             <span class="comment">% verifies that x is exactly representable in k bit</span>
s = x'*x                    <span class="comment">% dot product in single precision</span>
t = fl(x)'*fl(x)            <span class="comment">% dot product in k-bit precision</span>
s-t                         <span class="comment">% difference of results</span>
</pre><pre class="codeoutput">ans =
  logical
   1
s =
  single
  1.1002e+03
fl-type t =
 +1.00010011000011001011101 * 2^10   
fl-type ans =
 +1.00000000000000000000000 * 2^-12  
</pre><p>Obviously the results computed in single precision and the fl-package do not coincide. This is due to a Matlab library routine to compute the dot product x'*x. Computed in a loop, the result by single precision and the fl-package are identical. To verify see</p><pre class="codeinput">s_loop = single(0);
<span class="keyword">for</span> i=1:1000                    <span class="comment">% dot product x'*x by conventional loop</span>
  s_loop = s_loop + x(i)*x(i);
<span class="keyword">end</span>
s_loop - s                      <span class="comment">% difference to Matlab library routine</span>
s_loop - t                      <span class="comment">% difference to fl-package</span>
</pre><pre class="codeoutput">ans =
  single
 -2.4414e-04
fl-type ans =
 +0.00000000000000000000000          
</pre><h2 id="5">Rounding into k bits</h2><p>The function 'fl' rounds a given double precision number into the current format and/or into a specified precision; the function 'double' is a typecast into double precision. Since fl-numbers are always a subset of IEEE754 double precision numbers, a typecast is always error-free.</p><pre class="codeinput">flinit(5,20);
x = fl(32)
y = fl(33)
double([x y])
[z,exact] = fl([32 33])
</pre><pre class="codeoutput">fl-type x =
 +1.0000 * 2^5    
fl-type y =
 +1.0000 * 2^5    
ans =
    32    32
fl-type z =
 +1.0000 * 2^5     +1.0000 * 2^5    
exact =
  1&times;2 logical array
   1   0
</pre><p>Here x=32 is representable in a single bit, so no rounding error occurs, but 33 needs 6 bits to be stored. Rounding tie to even produces the result y=32 in 5 bits. The second parameter 'exact' is (componentwise) 1 if no rounding error occured. It offers a simple possibility to check whether a double number fits into k bits.</p><h2 id="7">The relative rounding error unit</h2><p>Mathematically, the relative rounding error unit for k-bit arithmetic is 2^(-k), that is the maximal relative error when rounding a real number into the fl-format. However, it is known that just above a power of 2 the relative error is larger, and just below it is smaller.</p><pre class="codeinput">x = linspace(0,10,100000);
X = fl(x);
close
plot(x,relerr(x,X))
</pre><img vspace="5" hspace="5" src="dfl_01.png" alt=""> <h2 id="8">Basic operations</h2><p>The four basic operations are executed as usual, for example</p><pre class="codeinput">x = fl(11)
y = fl(3)
z = x*y
t = (-sqrt(y) + 1/y)*(1:3)
</pre><pre class="codeoutput">fl-type x =
 +1.0110 * 2^3    
fl-type y =
 +1.1000 * 2^1    
fl-type z =
 +1.0000 * 2^5    
fl-type t =
 -1.0111 * 2^0     -1.0111 * 2^1     -1.0001 * 2^2    
</pre><h2 id="9">Output format</h2><p>Often it is useful to see the bit pattern, the default for fl-numbers. To switch to ordinary display as a double precision number use</p><pre class="codeinput">flinit(<span class="string">'DisplayDouble'</span>)
z
</pre><pre class="codeoutput">===&gt; Display fl-variables as doubles
fl-type z =
    32
</pre><p>The bit representation of fl-numbers and double numbers can be displayed directly by</p><pre class="codeinput">d = 11
x = fl(d)
getbits(d)
getbits(x)
</pre><pre class="codeoutput">d =
    11
fl-type x =
    11
ans =
    ' +1.0110000000000000000000000000000000000000000000000000 * 2^3'
ans =
    ' +1.0110 * 2^3'
</pre><p>The display may be restricted to m bits as well:</p><pre class="codeinput">m = 10
getbits(d,m)
</pre><pre class="codeoutput">m =
    10
ans =
    ' +1.011000000 * 2^3'
</pre><h2 id="12">Checking theorems in k-bit arithmetic I</h2><p>As a basis for this toolbox we showed in</p><p>(*)  S.M. Rump: IEEE754 <img src="dfl_eq15636846968047188835.png" alt="$k$" style="width:6px;height:9px;">-bit arithmetic inherited by double precision, ACM TOMS, 43(3), 2017</p><p>that for fl-numbers A,B in k-bit precision and m&gt;=2k there is no double rounding when first computing the quotient in m-bits and then round the result into k-bits. That means</p><pre>  fl_k(A/B) = fl_k(fl_m(A/B))</pre><p>We test that by checking all pairs of fl-numbers in [1,2), see   "help flsequence".</p><pre class="codeinput">  k = 12;
  flinit(k,100);
  m = 2*k;
  tic
  A = flsequence(1,pred(2));        <span class="comment">% all fl-numbers in [1,2)</span>
  <span class="keyword">for</span> i=1:length(A)
    B = A(i);
    index = find( flround(A/B,k) ~= flround( flround(A/B,m) , k ) );
    <span class="keyword">if</span> any(index)
      Aindex = A(index)
      B
    <span class="keyword">end</span>
  <span class="keyword">end</span>
  t = toc
</pre><pre class="codeoutput">t =
    1.4699
</pre><p>Note that this is not a rigorous proof because there may be a double rounding in the computation of flround(A/B,m) and flround(A/B,k) because A/B is computed in double precision. There is a chicken-egg problem: If the statement is true, then it is proved since 53&gt;=m&gt;=k. Note that not writing the above code in vectorized form increases the computing time to more than one hour.</p><h2 id="14">Checking theorems in k-bit arithmetic II</h2><p>In p-precision floating-point arithmetic the true result of an operation op is rounded to the nearest p-precision number. Usually the relative error is bounded by u=2^(-p), the relative rounding error unit. It has been noted in that this can be improved into</p><pre>  |fl(a op b) - ( a op b)| &lt;= u/(1+u)|a op b| .</pre><p>It is easy to see that the improved bound is attained if and only if, up to scaling, the true result a op b is equal to 1+u. For addition this is easy to achieve, but what about multiplication?</p><p>As shown in</p><p>C.-P. Jeannerod and S.M. Rump: On relative errors of floating-point operations: Optimal bounds and applications. to appear in Math. Comp., 2017</p><p>that the estimate is sharp if and only if 2^p+1 is prime, i.e. it is a Fermat prime. For that it is necessary that p=2^k is a power of 2, and up to now only five Fermat primes are known for k in {0,1,2,3,4} corresponding to 2^p+1 in {3,5,17,257,65537}. That means the only exceptional precisions p we know of for which the estimate is not sharp are p in {1,2,4,8,16}.</p><p>We might want to check the theorem by the following code</p><pre class="codeinput">  flinit(<span class="string">'DisplayBits'</span>)
  setround(0)
  tic
  <span class="keyword">for</span> k=0:5
    <span class="keyword">if</span> k==5
      p = 10;
    <span class="keyword">else</span>
      p = 2^k;
    <span class="keyword">end</span>
    flinit(p,100);
    x = flsequence(1,2)';
    y = fl((1+2^(-p))./double(x));
    index = find( double(x).*double(y) == 1+2^(-p) );
    <span class="keyword">if</span> any(index)
      disp([<span class="string">'precision '</span> int2str(p) <span class="string">' bits: examples for sharp estimate:'</span>])
      examples = fl([x(index) y(index)])
    <span class="keyword">else</span>
      disp([<span class="string">'precision '</span> int2str(p) <span class="string">' bits: estimate is never sharp'</span>])
    <span class="keyword">end</span>
  <span class="keyword">end</span>
  toc
</pre><pre class="codeoutput">===&gt; Display fl-variables by bit representation
precision 1 bits: estimate is never sharp
precision 2 bits: estimate is never sharp
precision 4 bits: estimate is never sharp
precision 8 bits: estimate is never sharp
precision 16 bits: estimate is never sharp
precision 10 bits: examples for sharp estimate:
fl-type examples =
 +1.010000000 * 2^0     +1.100110100 * 2^-1   
 +1.010010000 * 2^0     +1.100100000 * 2^-1   
 +1.100100000 * 2^0     +1.010010000 * 2^-1   
 +1.100110100 * 2^0     +1.010000000 * 2^-1   
Elapsed time is 0.012698 seconds.
</pre><p>The last case p=10 is only for check.</p><h2 id="16">Predecessor and successor</h2><p>A sequence of consecutive k-bit fl-numbers may computed by</p><pre class="codeinput">flinit(12,100);
flinit(<span class="string">'DisplayDouble'</span>);
x = fl(32)
[ pred(x) x succ(x) succ(x,2) ]
</pre><pre class="codeoutput">===&gt; Display fl-variables as doubles
fl-type x =
    32
fl-type ans =
   31.9922   32.0000   32.0156   32.0313
</pre><h2 id="17">Vector and matrix operations</h2><p>Vector and matrix operations are supported as well, for example</p><pre class="codeinput">A = fl(reshape(1:16,4,4))
A + 25
</pre><pre class="codeoutput">fl-type A =
     1     5     9    13
     2     6    10    14
     3     7    11    15
     4     8    12    16
fl-type ans =
    26    30    34    38
    27    31    35    39
    28    32    36    40
    29    33    37    41
</pre><h2 id="18">Sparse matrices</h2><p>Sparse vectors and matrices of fl-numbers as well as fl-intervals are specified as usual.</p><pre class="codeinput">n = 4;
A = fl(band(circulant(1:n),1,2))
S = sparse(A)
[I,J] = find(S); IJ = [ I' ; J' ]
is_sp = issparse(S)
nnzS = nnz(S)
[p,q] = bandwidth(S)
</pre><pre class="codeoutput">fl-type A =
     1     2     3     0
     4     1     2     3
     0     4     1     2
     0     0     4     1
fl-type S =
   (1,1)        1
   (2,1)        4
   (1,2)        2
   (2,2)        1
   (3,2)        4
   (1,3)        3
   (2,3)        2
   (3,3)        1
   (4,3)        4
   (2,4)        3
   (3,4)        2
   (4,4)        1
IJ =
     1     2     1     2     3     1     2     3     4     2     3     4
     1     1     2     2     2     3     3     3     3     4     4     4
is_sp =
  logical
   1
nnzS =
    12
p =
     1
q =
     2
</pre><h2 id="19">Matrix routines</h2><p>Many of the usual operations for full and sparse matrices are avaliable in k-bit arithmetic.</p><pre class="codeinput">t = trace(S)
D = diag(S,-1)
</pre><pre class="codeoutput">fl-type t =
   (1,1)        4
fl-type D =
   (1,1)        4
   (2,1)        4
   (3,1)        4
</pre><p>The display routines for double intervals apply to fl-interval quantities as well.</p><pre class="codeinput">T = tril(intval(A))
intvalinit(<span class="string">'DisplayInfSup'</span>)
T
intvalinit(<span class="string">'DisplayMidRad'</span>)
T
</pre><pre class="codeoutput">fl-type intval T =
    1.0000    0.0000    0.0000    0.0000
    4.0000    1.0000    0.0000    0.0000
    0.0000    4.0000    1.0000    0.0000
    0.0000    0.0000    4.0000    1.0000
===&gt; Default display of intervals by infimum/supremum (e.g. [ 3.14 , 3.15 ])
fl-type intval T =
[    1.0000,    1.0000] [    0.0000,    0.0000] [    0.0000,    0.0000] [    0.0000,    0.0000] 
[    4.0000,    4.0000] [    1.0000,    1.0000] [    0.0000,    0.0000] [    0.0000,    0.0000] 
[    0.0000,    0.0000] [    4.0000,    4.0000] [    1.0000,    1.0000] [    0.0000,    0.0000] 
[    0.0000,    0.0000] [    0.0000,    0.0000] [    4.0000,    4.0000] [    1.0000,    1.0000] 
===&gt; Default display of intervals by midpoint/radius (e.g. &lt; 3.14 , 0.01 &gt;)
fl-type intval T =
&lt;    1.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; 
&lt;    4.0000,   0.0000&gt; &lt;    1.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; 
&lt;    0.0000,   0.0000&gt; &lt;    4.0000,   0.0000&gt; &lt;    1.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; 
&lt;    0.0000,   0.0000&gt; &lt;    0.0000,   0.0000&gt; &lt;    4.0000,   0.0000&gt; &lt;    1.0000,   0.0000&gt; 
</pre><h2 id="21">Doubled precision accumulation of dot products</h2><p>The difference between double precision computations and k-bit precision can be explored. The default for matrix products is accumulation of dot products in working precision to simulate k-bit precision for all operations. For summation and dot products, doubled precision accumulation is possible.</p><p>The following generates some Toeplitz matrix and computes a residual in double and in 24-bit precision.</p><pre class="codeinput">flinit(12,100)
flinit(<span class="string">'AccumulateDouble'</span>)
n = 4;
A = toeplitz(1:n)
Ainv = inv(A)
resdble = eye(n) - A*Ainv
resfl_24 = eye(n) - fl(A)*fl(Ainv)
</pre><pre class="codeoutput">ans =
    'Initialization of fl-format to 12 mantissa bits incl. impl. 1 and exponent range -99 .. 100 for normalized fl-numbers'
===&gt; fl-accumulation precision double the working precision
A =
     1     2     3     4
     2     1     2     3
     3     2     1     2
     4     3     2     1
Ainv =
   -0.4000    0.5000    0.0000    0.1000
    0.5000   -1.0000    0.5000    0.0000
    0.0000    0.5000   -1.0000    0.5000
    0.1000    0.0000    0.5000   -0.4000
resdble =
   1.0e-15 *
         0   -0.1480   -0.2220   -0.2220
   -0.1665    0.2220   -0.2220         0
   -0.0555    0.0370    0.1110   -0.1110
   -0.1665    0.0740   -0.1665         0
fl-type resfl_24 =
   1.0e-04 *
         0   -0.0000         0    0.9155
    0.3052         0         0    0.6104
    0.6104   -0.0000         0    0.3052
    0.9155   -0.0000         0         0
</pre><p>Note that using fl(eye(n)) in the last statement would not change the result because 1 and 0 is exactly representable in any k-bit precision.</p><p>The same computation with k-bit precision accumulation of dot products is as follows:</p><pre class="codeinput">flinit(<span class="string">'AccumulateSingle'</span>)
resfl_12 = eye(n) - fl(A)*fl(Ainv)
</pre><pre class="codeoutput">===&gt; fl-accumulation in working precision
fl-type resfl_12 =
   1.0e-03 *
         0   -0.0000         0         0
         0         0         0         0
    0.1831   -0.0000         0         0
    0.0916   -0.0000         0         0
</pre><p>As may be expected, some components are better, some are worse.</p><h2 id="24">Mixed precisions</h2><p>Mixed operations between fl-numbers and single or double numbers are first executed and then rounded. This is unambiguous if the double number is exactly representable in the specified k-bit precision. However, consider</p><pre class="codeinput">flinit(5,100);
x = fl(33)/fl(11)
y = 33/fl(11)
</pre><pre class="codeoutput">fl-type x =
    2.8750
fl-type y =
     3
</pre><p>Here fl(11)=11, so y is exactly equal to 3=fl(3), but fl(33)=32 so that x is not equal to y. The same happens for comparison:</p><pre class="codeinput">fl(32) &lt; fl(33)
fl(32) == fl(33)
fl(32) == 33
</pre><pre class="codeoutput">ans =
  logical
   0
ans =
  logical
   1
ans =
  logical
   0
</pre><p>For safety reasons, a warning is given when a newly specified format does not cover all quantities of the old fl-format. Special caution is necessary when mixing precisions.</p><h2 id="27">Operator precedence</h2><p>As usual, Matlab follows strictly the operator concept, and in particular the precedence of operators. Therefore special care is necessary when using mixed precisions. Consider</p><pre class="codeinput">x = 3 * 11 + fl(1)
y = fl(3) * 11 + 1
</pre><pre class="codeoutput">fl-type x =
    34
fl-type y =
    32
</pre><p>Here first 3*11 is executed in double precision in the computation of x, whereas the computation of y consists only of fl-number operations.</p><h2 id="29">Interval operations</h2><p>Intervals with fl-number as endpoints are supported as well. For example,</p><pre class="codeinput">format <span class="string">infsup</span>
x = infsup(fl(1),2)
3*x - 1
x/3
</pre><pre class="codeoutput">fl-type intval x =
[    1.0000,    2.0000] 
fl-type intval ans =
[    2.0000,    5.0000] 
fl-type intval ans =
[    0.3281,    0.6876] 
</pre><p>The syntax and semantic is as for intervals with double precision endpoints, rounding is always outwards.</p><pre class="codeinput">z = fl(infsup(32,33))
</pre><pre class="codeoutput">fl-type intval z =
[   32.0000,   34.0000] 
</pre><h2 id="31">Interval vectors and matrices</h2><p>Again interval vectors and matrices of fl-numbers as well as the operation between those are as usual.</p><pre class="codeinput">n = 4;
intvalinit(<span class="string">'Display_'</span>)
flinit(12,99)
A = midrad(fl(randn(n)),1e-3)
P = A*intval(A')
C = compmat(A)
</pre><pre class="codeoutput">===&gt; Default display of intervals with uncertainty (e.g. 3.14_), changed 
        to inf/sup or mid/rad if input too wide ans =
    'Initialization of fl-format to 12 mantissa bits incl. impl. 1 and exponent range -98 .. 99 for normalized fl-numbers'
fl-type intval A =
[   -0.0937,   -0.0916] [    1.4609,    1.4639] [   -0.0126,   -0.0105] [    0.2658,    0.2681] 
[    1.9326,    1.9356] [    0.5903,    0.5928] [   -1.6236,   -1.6206] [    0.0693,    0.0714] 
[   -1.3121,   -1.3090] [   -1.5127,   -1.5097] [    0.1056,    0.1077] [   -0.7754,   -0.7729] 
[   -1.3018,   -1.2988] [   -0.6644,   -0.6618] [   -0.4126,   -0.4104] [   -0.0047,   -0.0026] 
fl-type intval P =
    2.22__    0.7___   -2.3___   -0.8___
    0.7___    6.7___   -3.7___   -2.2___
   -2.3___   -3.7___    4.6___    2.7___
   -0.8___   -2.2___    2.7___    2.30__
C =
    0.0916   -1.4639   -0.0125   -0.2681
   -1.9355    0.5903   -1.6235   -0.0714
   -1.3120   -1.5127    0.1057   -0.7754
   -1.3018   -0.6643   -0.4126    0.0026
</pre><p>Note that by definition Ostrowski's comparison matrix is a point matrix.</p><h2 id="33">Specification of intervals</h2><p>There are many ways to produce the narrowest interval with k-bit endpoints including 0.1:</p><pre class="codeinput">flinit(<span class="string">'DisplayBits'</span>)
x1 = fl(intval(1)/10);
x2 = fl(intval(<span class="string">'0.1'</span>));
x3 = midrad(0.1,realmin);
[ x1 x2 x3 ]'
</pre><pre class="codeoutput">===&gt; Display fl-variables by bit representation
fl-type intval ans =
 [ +1.10011001100 * 2^-4   , +1.10011001101 * 2^-4   ] 
 [ +1.10011001100 * 2^-4   , +1.10011001101 * 2^-4   ] 
 [ +1.10011001100 * 2^-4   , +1.10011001101 * 2^-4   ] 
</pre><p>Note that x3 is correct because first the interval midrad(0.1,realmin) with double precision endpoints is computed, then it is rounded into the specified k-bit precision.</p><h2 id="35">Directed rounding</h2><p>All operations and in particular a type cast from double into fl-numbers respect the current rounding mode. For example,</p><pre class="codeinput">setround(1)         <span class="comment">% rounding upwards</span>
32 + fl(1)
x = fl(33)
setround(0)
</pre><pre class="codeoutput">fl-type ans =
 +1.00001000000 * 2^5    
fl-type x =
 +1.00001000000 * 2^5    
</pre><h2 id="36">Mixing precision and double rounding</h2><p>The function flround(d,k) rounds d, a double number or interval, into k-bit precision, see help flround.</p><p>Concerning double rounding of the square root, I proved in the mentioned paper (*) the following. Suppose the square root of a k-bit number X is first rounded into m bits with result g, and then g is rounded into k bits, then this is equal to rounding the square root of X directly into k bits provided m&gt;=2k+2. Moreover, for m=2k+1 there is exactly one counterexample to that statement namely, up to scaling, the predecessor of 2. For k=12 this is checked as follows:</p><pre class="codeinput">k = 12;
flinit(k,100);
tic
X = flsequence(1,pred(4));      <span class="comment">% All k-bit fl-numbers in [1,4)</span>
sizeX = size(X)
<span class="keyword">for</span> m=(2*k+1):(2*k+2)
  m
  sqrtX = sqrt(double(X));
  g = flround(sqrtX,m);
  index = find( flround(sqrtX,k)~=flround(g,k) );
  <span class="keyword">if</span> any(index)
    getbits(X(index),k)         <span class="comment">% prints counterexample</span>
  <span class="keyword">else</span>
    disp(<span class="string">'no counterexample'</span>)
  <span class="keyword">end</span>
<span class="keyword">end</span>
toc
</pre><pre class="codeoutput">sizeX =
           1        4096
m =
    25
ans =
    ' +1.11111111111 * 2^1'
m =
    26
no counterexample
Elapsed time is 0.006158 seconds.
</pre><p>It may be a hint, but this is not quite a proof of correctness; even not for k=12 because in flround(sqrtX,k) or the computation of g a double rounding might have occured.</p><h2 id="38">Enjoy INTLAB</h2><p>INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing, Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2017b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% DEMOFL  A demonstration of fl-numbers: k-bit arithmetic

%% Initialization
% Recently we published some papers showing that in the famous Wilkinson
% estimates factors gamma_n can often be replaced by n*eps. For testing
% purposes, the fl-package simulates IEEE 754 k-bit arithmetic including
% over- and underflow, exceptional values, directed rounding and alike.
%
% To work, for example, with k bits precision and exponent range -E+1 ... E use

k = 5;
E = 20;
flinit(k,E);

%%
% The precision and the exponent range are limited to
%
%   1 <= prec <= 26   and   1 <= expBias <= 484
%
% in order to achieve high performance of all operations.
% To retrieve the current setting of precision and exponent range use

flinit

%% Comparison to IEEE754 single precision
% Using flinit(24,127), the set of fl-numbers is identical to IEEE754 single precision.
% However, library routines in Matlab may use a different order to compute,
% for example, dot products, so that results in single and fl-arithmetic
% may be different. Consider

flinit(24,127);             % same as IEEE754 single precision
x = single(randn(1000,1));  % random single precision vector
all(x == fl(x))             % verifies that x is exactly representable in k bit
s = x'*x                    % dot product in single precision
t = fl(x)'*fl(x)            % dot product in k-bit precision
s-t                         % difference of results

%%
% Obviously the results computed in single precision and the fl-package do 
% not coincide. This is due to a Matlab library routine to compute the dot
% product x'*x. Computed in a loop, the result by single precision and the
% fl-package are identical. To verify see

s_loop = single(0);
for i=1:1000                    % dot product x'*x by conventional loop
  s_loop = s_loop + x(i)*x(i);
end
s_loop - s                      % difference to Matlab library routine
s_loop - t                      % difference to fl-package

%% Rounding into k bits
% The function 'fl' rounds a given double precision number into the current
% format and/or into a specified precision; the function 'double' is a
% typecast into double precision. Since fl-numbers are always a subset of
% IEEE754 double precision numbers, a typecast is always error-free.

flinit(5,20);
x = fl(32)
y = fl(33)
double([x y])
[z,exact] = fl([32 33])

%%
% Here x=32 is representable in a single bit, so no rounding error occurs, but
% 33 needs 6 bits to be stored. Rounding tie to even produces the result
% y=32 in 5 bits. The second parameter 'exact' is (componentwise) 1 if no
% rounding error occured. It offers a simple possibility to check whether a double
% number fits into k bits.

%% The relative rounding error unit
% Mathematically, the relative rounding error unit for k-bit arithmetic is
% 2^(-k), that is the maximal relative error when rounding a real number
% into the fl-format. However, it is known that just above a power of 2 the
% relative error is larger, and just below it is smaller.

x = linspace(0,10,100000);
X = fl(x);
close
plot(x,relerr(x,X))

%% Basic operations
% The four basic operations are executed as usual, for example

x = fl(11)
y = fl(3)
z = x*y
t = (-sqrt(y) + 1/y)*(1:3)

%% Output format
% Often it is useful to see the bit pattern, the default for fl-numbers. 
% To switch to ordinary display as a double precision number use

flinit('DisplayDouble')
z

%%
% The bit representation of fl-numbers and double numbers can be displayed 
% directly by

d = 11
x = fl(d)
getbits(d)
getbits(x)

%%
% The display may be restricted to m bits as well:

m = 10
getbits(d,m)

%% Checking theorems in k-bit arithmetic I
% As a basis for this toolbox we showed in 
%
% (*)  S.M. Rump: IEEE754 $k$-bit arithmetic inherited by double precision, 
% ACM TOMS, 43(3), 2017
%
% that for fl-numbers A,B in
% k-bit precision and m>=2k there is no double rounding when first computing
% the quotient in m-bits and then round the result into k-bits. That means
%
%    fl_k(A/B) = fl_k(fl_m(A/B))
%
% We test that by checking all pairs of fl-numbers in [1,2), see 
%   "help flsequence".

  k = 12;
  flinit(k,100);
  m = 2*k;
  tic
  A = flsequence(1,pred(2));        % all fl-numbers in [1,2)
  for i=1:length(A)
    B = A(i);
    index = find( flround(A/B,k) ~= flround( flround(A/B,m) , k ) );
    if any(index)
      Aindex = A(index)
      B
    end
  end
  t = toc
  
%%
% Note that this is not a rigorous proof because there may be a double
% rounding in the computation of flround(A/B,m) and flround(A/B,k) because
% A/B is computed in double precision.
% There is a chicken-egg problem: If the statement is true, then it is
% proved since 53>=m>=k. 
% Note that not writing the above code in vectorized form increases the
% computing time to more than one hour.

%% Checking theorems in k-bit arithmetic II
% In p-precision floating-point arithmetic the true result of an
% operation op is rounded to the nearest p-precision number. Usually the
% relative error is bounded by u=2^(-p), the relative rounding error unit.
% It has been noted in that this can be improved into
%
%    |fl(a op b) - ( a op b)| <= u/(1+u)|a op b| .
%
% It is easy to see that the improved bound is attained if and only if, up to
% scaling, the true result a op b is equal to 1+u. For addition this is
% easy to achieve, but what about multiplication?
%
% As shown in 
%
% C.-P. Jeannerod and S.M. Rump: On relative errors of 
% floating-point operations: Optimal bounds and applications. 
% to appear in Math. Comp., 2017
%
% that the estimate is sharp if and only if
% 2^p+1 is prime, i.e. it is a Fermat prime. For that it is necessary that p=2^k is a
% power of 2, and up to now only five Fermat primes are known for k in
% {0,1,2,3,4} corresponding to 2^p+1 in {3,5,17,257,65537}. That means the
% only exceptional precisions p we know of for which the estimate is not
% sharp are p in {1,2,4,8,16}.
%
% We might want to check the theorem by the following code

  flinit('DisplayBits')
  setround(0)
  tic
  for k=0:5
    if k==5
      p = 10;
    else
      p = 2^k;
    end
    flinit(p,100);
    x = flsequence(1,2)';
    y = fl((1+2^(-p))./double(x));
    index = find( double(x).*double(y) == 1+2^(-p) );
    if any(index)
      disp(['precision ' int2str(p) ' bits: examples for sharp estimate:'])
      examples = fl([x(index) y(index)])
    else
      disp(['precision ' int2str(p) ' bits: estimate is never sharp'])
    end
  end
  toc
  
%%
% The last case p=10 is only for check.

%% Predecessor and successor
% A sequence of consecutive k-bit fl-numbers may computed by

flinit(12,100);
flinit('DisplayDouble');
x = fl(32)
[ pred(x) x succ(x) succ(x,2) ]

%% Vector and matrix operations
% Vector and matrix operations are supported as well, for example

A = fl(reshape(1:16,4,4))
A + 25

%% Sparse matrices
% Sparse vectors and matrices of fl-numbers as well as fl-intervals are
% specified as usual.

n = 4;
A = fl(band(circulant(1:n),1,2))
S = sparse(A)
[I,J] = find(S); IJ = [ I' ; J' ]
is_sp = issparse(S)
nnzS = nnz(S)
[p,q] = bandwidth(S)

%% Matrix routines
% Many of the usual operations for full and sparse matrices are avaliable
% in k-bit arithmetic.

t = trace(S)
D = diag(S,-1)

%%
% The display routines for double intervals apply to fl-interval quantities
% as well.

T = tril(intval(A))
intvalinit('DisplayInfSup')
T
intvalinit('DisplayMidRad')
T

%% Doubled precision accumulation of dot products
% The difference between double precision computations and k-bit precision
% can be explored. 
% The default for matrix products is accumulation of dot products in
% working precision to simulate k-bit precision for all operations. For 
% summation and dot products, doubled precision accumulation is possible.
%
% The following generates some Toeplitz matrix and computes a 
% residual in double and in 24-bit precision.

flinit(12,100)
flinit('AccumulateDouble')
n = 4;
A = toeplitz(1:n)
Ainv = inv(A)
resdble = eye(n) - A*Ainv
resfl_24 = eye(n) - fl(A)*fl(Ainv)

%%
% Note that using fl(eye(n)) in the last statement would not change the
% result because 1 and 0 is exactly representable in any k-bit precision.
%
% The same computation with k-bit precision accumulation of dot products is
% as follows:

flinit('AccumulateSingle')
resfl_12 = eye(n) - fl(A)*fl(Ainv)

%%
% As may be expected, some components are better, some are worse. 

%% Mixed precisions
% Mixed operations between fl-numbers and single or double numbers are
% first executed and then rounded. This is unambiguous if the double number
% is exactly representable in the specified k-bit precision. However,
% consider

flinit(5,100);
x = fl(33)/fl(11)
y = 33/fl(11)

%%
% Here fl(11)=11, so y is exactly equal to 3=fl(3), but fl(33)=32 so that x
% is not equal to y. The same happens for comparison:

fl(32) < fl(33)
fl(32) == fl(33)
fl(32) == 33

%%
% For safety reasons, a warning is given when a newly specified format does
% not cover all quantities of the old fl-format. Special caution is necessary
% when mixing precisions.

%% Operator precedence
% As usual, Matlab follows strictly the operator concept, and in particular
% the precedence of operators. Therefore special care is necessary when using 
% mixed precisions. Consider

x = 3 * 11 + fl(1)
y = fl(3) * 11 + 1

%%
% Here first 3*11 is executed in double precision in the computation of x,
% whereas the computation of y consists only of fl-number operations.

%% Interval operations
% Intervals with fl-number as endpoints are supported as well. For example,

format infsup
x = infsup(fl(1),2)
3*x - 1
x/3

%%
% The syntax and semantic is as for intervals with double precision
% endpoints, rounding is always outwards.

z = fl(infsup(32,33))

%% Interval vectors and matrices
% Again interval vectors and matrices of fl-numbers as well as the
% operation between those are as usual.

n = 4;
intvalinit('Display_')
flinit(12,99)
A = midrad(fl(randn(n)),1e-3)
P = A*intval(A')
C = compmat(A)

%%
% Note that by definition Ostrowski's comparison matrix is a point matrix.

%% Specification of intervals
% There are many ways to produce the narrowest interval with k-bit
% endpoints including 0.1:

flinit('DisplayBits')
x1 = fl(intval(1)/10);
x2 = fl(intval('0.1'));
x3 = midrad(0.1,realmin);
[ x1 x2 x3 ]'

%%
% Note that x3 is correct because first the interval midrad(0.1,realmin)
% with double precision endpoints is computed, then it is rounded into the
% specified k-bit precision.

%% Directed rounding
% All operations and in particular a type cast from double into fl-numbers
% respect the current rounding mode. For example,

setround(1)         % rounding upwards
32 + fl(1)
x = fl(33)
setround(0)

%% Mixing precision and double rounding
% The function flround(d,k) rounds d, a double number or interval, 
% into k-bit precision, see help flround. 
%
% Concerning double rounding of the square root, I proved in the mentioned
% paper (*) the following.
% Suppose the square root of a k-bit number X is first rounded into m bits with result g,
% and then g is rounded into k bits, then this is equal to rounding the
% square root of X
% directly into k bits provided m>=2k+2. Moreover, for m=2k+1 there is
% exactly one counterexample to that statement namely, up to scaling, the 
% predecessor of 2. For k=12 this is checked as follows:

k = 12;
flinit(k,100);
tic
X = flsequence(1,pred(4));      % All k-bit fl-numbers in [1,4)
sizeX = size(X)
for m=(2*k+1):(2*k+2)
  m
  sqrtX = sqrt(double(X));
  g = flround(sqrtX,m);
  index = find( flround(sqrtX,k)~=flround(g,k) );
  if any(index)
    getbits(X(index),k)         % prints counterexample
  else
    disp('no counterexample')
  end
end
toc

%%
% It may be a hint, but this is not quite a proof of correctness;
% even not for k=12 because in 
% flround(sqrtX,k) or the computation of g a double rounding might have
% occured. 

%% Enjoy INTLAB
% INTLAB was designed and written by S.M. Rump, head of the Institute for Reliable Computing,
% Hamburg University of Technology. Suggestions are always welcome to rump (at) tuhh.de

 
##### SOURCE END #####
--></body></html>